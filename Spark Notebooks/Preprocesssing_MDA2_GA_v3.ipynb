{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19464f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68368f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e31ad17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark3/jars/spark-unsafe_2.12-3.2.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"MDA2-Group Assignment\")\n",
    "    .getOrCreate())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a513e9a",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "### Dataset Info\n",
    "\n",
    "This step is only needed in our course environment; other Spark environments you might see out there might not need this statement.\n",
    "\n",
    "Each quarter, we publish downloadable files of Capital Bikeshare trip data. The data includes:\n",
    "\n",
    "- **Duration** – Duration of trip\n",
    "- **Start Date** – Includes start date and time\n",
    "- **End Date** – Includes end date and time\n",
    "- **Start Station** – Includes starting station name and number\n",
    "- **End Station** – Includes ending station name and number\n",
    "- **Bike Number** – Includes ID number of bike used for the trip\n",
    "- **Member Type** – Indicates whether user was a \"registered\" member (Annual Member, 30-Day Member, or Day Key Member) or a \"casual\" rider (Single Trip, 24-Hour Pass, 3-Day Pass, or 5-Day Pass)\n",
    "\n",
    "This data has been processed to remove trips that are taken by staff as they service and inspect the system, trips that are taken to/from any of our “test” stations at our warehouses, and any trips lasting less than 60 seconds (potentially false starts or users trying to re-dock a bike to ensure it's secure).\n",
    "\n",
    "**NOTE**: The 3-Day Membership replaced the 5-Day Membership in Fall 2011.\n",
    "\n",
    "https://capitalbikeshare.com/system-data\n",
    "\n",
    "\n",
    "**IMPORTANT** **this documentation only applies for the CSV files up to March, 2020 (2020 Q1). From April, 2020, onwards, the schema for the data changes to this form (adding new columns):**\n",
    "\n",
    "- ride_id                object\n",
    "- rideable_type          object\n",
    "- started_at             object\n",
    "- ended_at               object\n",
    "- start_station_name     object\n",
    "- start_station_id      float64\n",
    "- end_station_name       object\n",
    "- end_station_id        float64\n",
    "- start_lat             float64\n",
    "- start_lng             float64\n",
    "- end_lat               float64\n",
    "- end_lng               float64\n",
    "- member_casual          object --> = Member Type\n",
    "\n",
    "dtype: object\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc223a1",
   "metadata": {},
   "source": [
    "WE DECIDED TO ONLY WORK WITH THE DATA STARTING FROM APRIL 2020 -ONLY WITH THE CSV FILES THAT HAD THE NEWER SHCEMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8199ae00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom pyspark.sql.types import StructType, StructField, StringType, TimestampType\\n\\n# Define the schema explicitly\\nschema = StructType([\\n    StructField(\"Duration\", StringType(), True),\\n    StructField(\"Start date\", StringType(), True),\\n    StructField(\"End date\", StringType(), True),\\n    StructField(\"Start station number\", StringType(), True),\\n    StructField(\"Start station\", StringType(), True),\\n    StructField(\"End station number\", StringType(), True),\\n    StructField(\"End station\", StringType(), True),\\n    StructField(\"Bike number\", StringType(), True),\\n    StructField(\"Member type\", StringType(), True)\\n])\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType\n",
    "\n",
    "# Define the schema explicitly\n",
    "schema = StructType([\n",
    "    StructField(\"Duration\", StringType(), True),\n",
    "    StructField(\"Start date\", StringType(), True),\n",
    "    StructField(\"End date\", StringType(), True),\n",
    "    StructField(\"Start station number\", StringType(), True),\n",
    "    StructField(\"Start station\", StringType(), True),\n",
    "    StructField(\"End station number\", StringType(), True),\n",
    "    StructField(\"End station\", StringType(), True),\n",
    "    StructField(\"Bike number\", StringType(), True),\n",
    "    StructField(\"Member type\", StringType(), True)\n",
    "])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, FloatType, IntegerType\n",
    "\n",
    "# Define the schema explicitly\n",
    "schema = StructType([\n",
    "    StructField(\"\", IntegerType(), True),\n",
    "    StructField(\"ride_id\", StringType(), True),\n",
    "    StructField(\"rideable_type\", StringType(), True),\n",
    "    StructField(\"started_at\", StringType(), True),\n",
    "    StructField(\"ended_at\", StringType(), True),\n",
    "    StructField(\"start_station_name\", StringType(), True),\n",
    "    StructField(\"start_station_id\", FloatType(), True),\n",
    "    StructField(\"end_station_name\", StringType(), True),\n",
    "    StructField(\"end_station_id\", FloatType(), True),\n",
    "    StructField(\"start_lat\", FloatType(), True),\n",
    "    StructField(\"start_lng\", FloatType(), True),\n",
    "    StructField(\"end_lat\", FloatType(), True),\n",
    "    StructField(\"end_lng\", FloatType(), True),\n",
    "    StructField(\"member_casual\", StringType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d427ed75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ride_id: string (nullable = true)\n",
      " |-- rideable_type: string (nullable = true)\n",
      " |-- started_at: string (nullable = true)\n",
      " |-- ended_at: string (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_id: float (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_id: float (nullable = true)\n",
      " |-- start_lat: float (nullable = true)\n",
      " |-- start_lng: float (nullable = true)\n",
      " |-- end_lat: float (nullable = true)\n",
      " |-- end_lng: float (nullable = true)\n",
      " |-- member_casual: string (nullable = true)\n",
      "\n",
      "+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+---------+---------+----------+-------------+\n",
      "|         ride_id|rideable_type|         started_at|           ended_at|  start_station_name|start_station_id|    end_station_name|end_station_id|start_lat|start_lng|  end_lat|   end_lng|member_casual|\n",
      "+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+---------+---------+----------+-------------+\n",
      "|6D3E254769125C2D| classic_bike|2022-02-11 14:46:17|2022-02-11 15:01:29|       5th & K St NW|         31600.0| 14th & Irving St NW|       31124.0| 38.90304|-77.01903| 38.92855| -77.03223|       casual|\n",
      "|3A7A82A4900DD588| classic_bike|2022-02-09 07:34:02|2022-02-09 07:45:12|       5th & K St NW|         31600.0|17th & K St NW / ...|       31233.0| 38.90304|-77.01903| 38.90206| -77.03832|       member|\n",
      "|90AD42BB3F5466A5| classic_bike|2022-02-20 17:49:34|2022-02-20 17:53:42|       5th & K St NW|         31600.0|       8th & O St NW|       31281.0| 38.90304|-77.01903| 38.90864| -77.02277|       member|\n",
      "|93AD2E3F1DA185A8| classic_bike|2022-02-10 13:00:47|2022-02-10 13:06:46|       5th & K St NW|         31600.0|       8th & O St NW|       31281.0| 38.90304|-77.01903| 38.90864| -77.02277|       member|\n",
      "|0D764E7E47A7E3E4| classic_bike|2022-02-26 09:19:40|2022-02-26 09:34:04|       5th & K St NW|         31600.0|      23rd & M St NW|       31128.0| 38.90304|-77.01903|38.905304| -77.05026|       member|\n",
      "|B7454BBF6B95E1DB| classic_bike|2022-02-11 12:40:23|2022-02-11 13:10:33|       4th & W St NE|         31500.0|New Hampshire Ave...|       31275.0| 38.91908|-77.00065|38.901756| -77.05109|       casual|\n",
      "|381CE87801764E01| classic_bike|2022-02-18 17:51:10|2022-02-18 18:06:09|       5th & K St NW|         31600.0|17th & Corcoran S...|       31214.0| 38.90304|-77.01903|  38.9121|  -77.0387|       casual|\n",
      "|858D06F467A67B17| classic_bike|2022-02-11 14:13:08|2022-02-11 14:30:29|       4th & W St NE|         31500.0|       4th & W St NE|       31500.0| 38.91908|-77.00065| 38.91908| -77.00065|       member|\n",
      "|1013E0D884AFE50C| classic_bike|2022-02-06 15:54:55|2022-02-06 16:00:39|       5th & K St NW|         31600.0|Metro Center / 12...|       31230.0| 38.90304|-77.01903|38.898365| -77.02787|       member|\n",
      "|91DBE6C402C3EEAD| classic_bike|2022-02-18 20:25:34|2022-02-18 20:26:33|      15th & L St NW|         31276.0|      15th & M St NW|       31298.0| 38.90365|-77.03492|38.905422|-77.034676|       member|\n",
      "|4032781C4B13D383| classic_bike|2022-02-18 20:29:08|2022-02-18 20:30:10|      15th & L St NW|         31276.0|      15th & M St NW|       31298.0| 38.90365|-77.03492|38.905422|-77.034676|       member|\n",
      "|70896675C39F78D7| classic_bike|2022-02-18 20:21:58|2022-02-18 20:22:55|      15th & L St NW|         31276.0|      15th & M St NW|       31298.0| 38.90365|-77.03492|38.905422|-77.034676|       member|\n",
      "|4815A2D9B1FBB39D| classic_bike|2022-02-17 20:02:36|2022-02-17 20:20:55|      15th & L St NW|         31276.0|18th St & Wyoming...|       31114.0| 38.90365|-77.03492|38.918808| -77.04157|       member|\n",
      "|A993603123FCE83D| classic_bike|2022-02-01 18:10:52|2022-02-01 18:29:26|Potomac Ave & 35t...|         31052.0|Main Line Blvd & ...|       31959.0|38.844013|-77.05054| 38.83243|-77.049774|       member|\n",
      "|0AA710AFF552664E| classic_bike|2022-02-26 14:24:18|2022-02-26 14:46:35|      15th & L St NW|         31276.0|  Half & Water St SW|       31664.0| 38.90365|-77.03492|38.866276| -77.01055|       member|\n",
      "|2542C5C6748DC7A2| classic_bike|2022-02-23 16:28:52|2022-02-23 16:39:36|Potomac Ave & Hal...|         31648.0|       3rd & G St SE|       31625.0|38.869682|-77.01082|38.881184| -77.00183|       member|\n",
      "|A023C292A30EFB62| classic_bike|2022-02-13 14:29:21|2022-02-13 14:48:07|       5th & K St NW|         31600.0| 11th & Kenyon St NW|       31102.0| 38.90304|-77.01903|38.929462|-77.027824|       member|\n",
      "|919502E886F76283| classic_bike|2022-02-27 19:07:35|2022-02-27 19:11:47|Carlin Springs Rd...|         31919.0| Utah St & 11th St N|       31049.0|38.876694|-77.11298| 38.88367| -77.11391|       member|\n",
      "|FE4A6843A96BCA3F| classic_bike|2022-02-26 20:14:47|2022-02-26 20:31:15|Potomac Ave & Hal...|         31648.0|Potomac Ave & 8th...|       31635.0|38.869682|-77.01082|38.876736| -76.99447|       member|\n",
      "|8621F90CC173EB12| classic_bike|2022-02-27 15:03:54|2022-02-27 15:16:43|Potomac Ave & 35t...|         31052.0|Potomac Ave & Swa...|       31916.0|38.844013|-77.05054|38.829544|-77.047844|       member|\n",
      "+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+---------+---------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read a single CSV file to check schema\n",
    "single_file_df = spark.read.schema(schema).option(\"header\", \"true\").csv(\"hdfs://localhost:9000/datalake/raw/bike_sharing/bike_sharing/202202-capitalbikeshare-tripdata.csv\")\n",
    "\n",
    "# Show the DataFrame to verify the schema\n",
    "single_file_df.printSchema()\n",
    "single_file_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[: float, ride_id: string, rideable_type: string, started_at: string, ended_at: string, start_station_name: string, start_station_id: float, end_station_name: string, end_station_id: float, start_lat: float, start_lng: float, end_lat: float, end_lng: float, member_casual: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitalbikeshare_raw.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "354088b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+---------+--------+---------+-------------+\n",
      "|   |         ride_id|rideable_type|         started_at|           ended_at|  start_station_name|start_station_id|    end_station_name|end_station_id|start_lat|start_lng| end_lat|  end_lng|member_casual|\n",
      "+---+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+---------+--------+---------+-------------+\n",
      "|  0|77A0F1B26D1597B1|  docked_bike|2020-04-25 17:28:39|2020-04-25 17:35:04|Rhode Island & Co...|         31239.0|      12th & L St NW|       31251.0|38.905994| -77.0398|38.90382| -77.0284|       casual|\n",
      "|  1|8698F10128EA4F18|  docked_bike|2020-04-06 07:54:59|2020-04-06 07:57:24|      21st & I St NW|         31205.0|      18th & L St NW|       31224.0| 38.90071|-77.04645|38.90374|-77.04245|       member|\n",
      "|  2|AA07819DC0F58872|  docked_bike|2020-04-22 17:06:18|2020-04-22 18:08:32|Connecticut Ave &...|         31313.0|Connecticut Ave &...|       31313.0| 38.94114|-77.06197|38.94114|-77.06197|       casual|\n",
      "|  3|DA909BCA92EF85AB|  docked_bike|2020-04-16 15:22:40|2020-04-16 15:58:37|       7th & E St SW|         31294.0|       7th & E St SW|       31294.0| 38.88345|-77.02174|38.88345|-77.02174|       casual|\n",
      "|  4|B36F1E14D8C6757E|  docked_bike|2020-04-10 13:19:41|2020-04-10 13:23:05|Potomac & Pennsyl...|         31606.0|8th & Eye St SE /...|       31608.0|  38.8803| -76.9862| 38.8792| -76.9953|       member|\n",
      "+---+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+---------+--------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read all CSV files in the directory using the defined schema\n",
    "capitalbikeshare_raw = spark.read.schema(schema).option(\"header\", \"true\").csv(\"hdfs://localhost:9000/datalake/raw/bike_sharing/final_data.csv\")\n",
    "capitalbikeshare_raw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba932268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[: int, ride_id: string, rideable_type: string, started_at: string, ended_at: string, start_station_name: string, start_station_id: float, end_station_name: string, end_station_id: float, start_lat: float, start_lng: float, end_lat: float, end_lng: float, member_casual: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cache the DataFrame if needed\n",
    "capitalbikeshare_raw.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "346be032",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ride_id: string (nullable = true)\n",
      " |-- rideable_type: string (nullable = true)\n",
      " |-- started_at: string (nullable = true)\n",
      " |-- ended_at: string (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_id: float (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_id: float (nullable = true)\n",
      " |-- start_lat: float (nullable = true)\n",
      " |-- start_lng: float (nullable = true)\n",
      " |-- end_lat: float (nullable = true)\n",
      " |-- end_lng: float (nullable = true)\n",
      " |-- member_casual: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=======================================================> (38 + 1) / 39]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 22511604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print the schema to verify\n",
    "capitalbikeshare_raw.printSchema()\n",
    "\n",
    "# Perform a count to ensure there are no read errors\n",
    "print(f\"Number of records: {capitalbikeshare_raw.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e09ae9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=================================================>      (15 + 2) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-------------------+\n",
      "|summary|   started_at|           ended_at|\n",
      "+-------+-------------+-------------------+\n",
      "|  count|     11246784|           11246784|\n",
      "|    min| classic_bike|2020-04-01 00:25:48|\n",
      "|    max|electric_bike|2023-09-30 23:59:58|\n",
      "+-------+-------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check for nulls or other anomalies in the 'started_at' and 'ended_at' columns as they have caused a lot of trouble\n",
    "capitalbikeshare_raw.select(\"started_at\", \"ended_at\").summary(\"count\", \"min\", \"max\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:==================================================>      (15 + 2) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|rideable_type|  count|\n",
      "+-------------+-------+\n",
      "| classic_bike|7129646|\n",
      "|electric_bike|2185882|\n",
      "|  docked_bike|1931256|\n",
      "+-------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "value_counts_df = capitalbikeshare_raw.groupBy(\"rideable_type\").count().orderBy(F.desc(\"count\"))\n",
    "value_counts_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6befb40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only if I need to restart the process from the beginning...\n",
    "'''\n",
    "capitalbikeshare_raw = capitalbikeshare_raw_copy\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59ded462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ride_id</td>\n",
       "      <td>rideable_type</td>\n",
       "      <td>started_at</td>\n",
       "      <td>ended_at</td>\n",
       "      <td>start_station_name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>end_station_name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>member_casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D88F352076694FFC</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-08-03 17:33:41</td>\n",
       "      <td>2023-08-03 18:03:07</td>\n",
       "      <td>5th St &amp; Massachusetts Ave NW</td>\n",
       "      <td>31265.0</td>\n",
       "      <td>20th &amp; Columbia Rd NW</td>\n",
       "      <td>31133.0</td>\n",
       "      <td>38.900928</td>\n",
       "      <td>-77.018677</td>\n",
       "      <td>38.918037</td>\n",
       "      <td>-77.045486</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6B733406B1E19446</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-08-16 08:19:26</td>\n",
       "      <td>2023-08-16 08:34:07</td>\n",
       "      <td>5th &amp; K St NW</td>\n",
       "      <td>31600.0</td>\n",
       "      <td>23rd &amp; E St NW</td>\n",
       "      <td>31260.0</td>\n",
       "      <td>38.903042</td>\n",
       "      <td>-77.019028</td>\n",
       "      <td>38.896103</td>\n",
       "      <td>-77.049881</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56145CE76A7B5A66</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-08-25 08:19:20</td>\n",
       "      <td>2023-08-25 08:37:11</td>\n",
       "      <td>5th &amp; K St NW</td>\n",
       "      <td>31600.0</td>\n",
       "      <td>23rd &amp; E St NW</td>\n",
       "      <td>31260.0</td>\n",
       "      <td>38.903042</td>\n",
       "      <td>-77.019028</td>\n",
       "      <td>38.896103</td>\n",
       "      <td>-77.049881</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11B7E5D90AE9DBE5</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-08-15 17:56:22</td>\n",
       "      <td>2023-08-15 18:13:58</td>\n",
       "      <td>23rd &amp; E St NW</td>\n",
       "      <td>31260.0</td>\n",
       "      <td>5th &amp; K St NW</td>\n",
       "      <td>31600.0</td>\n",
       "      <td>38.896103</td>\n",
       "      <td>-77.049881</td>\n",
       "      <td>38.903042</td>\n",
       "      <td>-77.019028</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type           started_at             ended_at  \\\n",
       "0           ride_id  rideable_type           started_at             ended_at   \n",
       "1  D88F352076694FFC   classic_bike  2023-08-03 17:33:41  2023-08-03 18:03:07   \n",
       "2  6B733406B1E19446   classic_bike  2023-08-16 08:19:26  2023-08-16 08:34:07   \n",
       "3  56145CE76A7B5A66   classic_bike  2023-08-25 08:19:20  2023-08-25 08:37:11   \n",
       "4  11B7E5D90AE9DBE5   classic_bike  2023-08-15 17:56:22  2023-08-15 18:13:58   \n",
       "\n",
       "              start_station_name  start_station_id       end_station_name  \\\n",
       "0             start_station_name               NaN       end_station_name   \n",
       "1  5th St & Massachusetts Ave NW           31265.0  20th & Columbia Rd NW   \n",
       "2                  5th & K St NW           31600.0        23rd & E St NW    \n",
       "3                  5th & K St NW           31600.0        23rd & E St NW    \n",
       "4                23rd & E St NW            31260.0          5th & K St NW   \n",
       "\n",
       "   end_station_id  start_lat  start_lng    end_lat    end_lng  member_casual  \n",
       "0             NaN        NaN        NaN        NaN        NaN  member_casual  \n",
       "1         31133.0  38.900928 -77.018677  38.918037 -77.045486         member  \n",
       "2         31260.0  38.903042 -77.019028  38.896103 -77.049881         member  \n",
       "3         31260.0  38.903042 -77.019028  38.896103 -77.049881         member  \n",
       "4         31600.0  38.896103 -77.049881  38.903042 -77.019028         member  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the original df into a 'safety' variable\n",
    "'''\n",
    "capitalbikeshare_raw_copy = capitalbikeshare_raw\n",
    "\n",
    "capitalbikeshare_raw_copy.limit(5).toPandas()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c15563fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:======================================>                  (8 + 4) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|started_at|\n",
      "+----------+\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp\n",
    "\n",
    "# Check for entries that are non-date values\n",
    "capitalbikeshare_raw.filter(~col(\"started_at\").rlike(\"^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}$\")).select(\"started_at\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:===============================================>        (33 + 3) / 39]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 44 rows. New total number of rows: 22511560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "\n",
    "# Get the first row of the DataFrame\n",
    "header = capitalbikeshare_raw.first()\n",
    "\n",
    "# Get the name of the first column\n",
    "first_column_name = capitalbikeshare_raw.columns[0]\n",
    "\n",
    "# Filter out the rows that have the same value as the header in the first row\n",
    "capitalbikeshare_filtered = capitalbikeshare_raw.filter(expr(\"NOT {} = '{}'\".format(first_column_name, header[0])))\n",
    "\n",
    "# Count the number of rows that were dropped or filtered\n",
    "num_dropped = capitalbikeshare_raw.count() - capitalbikeshare_filtered.count()\n",
    "\n",
    "# Print the number of rows that were dropped or filtered and the new total number of rows in the DataFrame\n",
    "print(f\"Dropped {num_dropped} rows. New total number of rows: {capitalbikeshare_filtered.count()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ride_id: string, rideable_type: string, started_at: string, ended_at: string, start_station_name: string, start_station_id: float, end_station_name: string, end_station_id: float, start_lat: float, start_lng: float, end_lat: float, end_lng: float, member_casual: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitalbikeshare_raw.unpersist()\n",
    "capitalbikeshare_filtered.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87db79da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C40CF15D0DBE584E</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-09-23 18:42:27</td>\n",
       "      <td>2022-09-24 08:27:11</td>\n",
       "      <td>Georgia Ave &amp; Morton St NW</td>\n",
       "      <td>31419.0</td>\n",
       "      <td>14th St Heights / 14th &amp; Crittenden St NW</td>\n",
       "      <td>31402.0</td>\n",
       "      <td>38.932129</td>\n",
       "      <td>-77.023499</td>\n",
       "      <td>38.947773</td>\n",
       "      <td>-77.032822</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3788C1944643B399</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-09-22 01:35:01</td>\n",
       "      <td>2022-09-22 01:49:59</td>\n",
       "      <td>7th &amp; T St NW</td>\n",
       "      <td>31109.0</td>\n",
       "      <td>7th St &amp; Massachusetts Ave NE</td>\n",
       "      <td>31647.0</td>\n",
       "      <td>38.915691</td>\n",
       "      <td>-77.021706</td>\n",
       "      <td>38.892220</td>\n",
       "      <td>-76.996017</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A9E14A3286BB0922</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-09-16 17:04:11</td>\n",
       "      <td>2022-09-16 17:08:40</td>\n",
       "      <td>7th &amp; F St NW / National Portrait Gallery</td>\n",
       "      <td>31232.0</td>\n",
       "      <td>North Capitol St &amp; F St NW</td>\n",
       "      <td>31624.0</td>\n",
       "      <td>38.897282</td>\n",
       "      <td>-77.022194</td>\n",
       "      <td>38.897446</td>\n",
       "      <td>-77.009888</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77518ADEB4313901</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-09-29 17:24:21</td>\n",
       "      <td>2022-09-29 18:32:05</td>\n",
       "      <td>14th &amp; D St NW / Ronald Reagan Building</td>\n",
       "      <td>31231.0</td>\n",
       "      <td>4th &amp; East Capitol St NE</td>\n",
       "      <td>31618.0</td>\n",
       "      <td>38.894512</td>\n",
       "      <td>-77.031616</td>\n",
       "      <td>38.889954</td>\n",
       "      <td>-77.000351</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7B99FCADC829EAC0</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-09-13 23:51:12</td>\n",
       "      <td>2022-09-14 00:35:14</td>\n",
       "      <td>New Hampshire Ave &amp; 24th St NW</td>\n",
       "      <td>31275.0</td>\n",
       "      <td>New Hampshire Ave &amp; 24th St NW</td>\n",
       "      <td>31275.0</td>\n",
       "      <td>38.901756</td>\n",
       "      <td>-77.051086</td>\n",
       "      <td>38.901756</td>\n",
       "      <td>-77.051086</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id rideable_type           started_at             ended_at  \\\n",
       "0  C40CF15D0DBE584E  classic_bike  2022-09-23 18:42:27  2022-09-24 08:27:11   \n",
       "1  3788C1944643B399  classic_bike  2022-09-22 01:35:01  2022-09-22 01:49:59   \n",
       "2  A9E14A3286BB0922  classic_bike  2022-09-16 17:04:11  2022-09-16 17:08:40   \n",
       "3  77518ADEB4313901  classic_bike  2022-09-29 17:24:21  2022-09-29 18:32:05   \n",
       "4  7B99FCADC829EAC0  classic_bike  2022-09-13 23:51:12  2022-09-14 00:35:14   \n",
       "\n",
       "                          start_station_name  start_station_id  \\\n",
       "0                 Georgia Ave & Morton St NW           31419.0   \n",
       "1                              7th & T St NW           31109.0   \n",
       "2  7th & F St NW / National Portrait Gallery           31232.0   \n",
       "3    14th & D St NW / Ronald Reagan Building           31231.0   \n",
       "4             New Hampshire Ave & 24th St NW           31275.0   \n",
       "\n",
       "                            end_station_name  end_station_id  start_lat  \\\n",
       "0  14th St Heights / 14th & Crittenden St NW         31402.0  38.932129   \n",
       "1              7th St & Massachusetts Ave NE         31647.0  38.915691   \n",
       "2                 North Capitol St & F St NW         31624.0  38.897282   \n",
       "3                   4th & East Capitol St NE         31618.0  38.894512   \n",
       "4             New Hampshire Ave & 24th St NW         31275.0  38.901756   \n",
       "\n",
       "   start_lng    end_lat    end_lng member_casual  \n",
       "0 -77.023499  38.947773 -77.032822        member  \n",
       "1 -77.021706  38.892220 -76.996017        member  \n",
       "2 -77.022194  38.897446 -77.009888        member  \n",
       "3 -77.031616  38.889954 -77.000351        casual  \n",
       "4 -77.051086  38.901756 -77.051086        casual  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitalbikeshare_filtered.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitalbikeshare_filtered = capitalbikeshare_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:==============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|started_at|\n",
      "+----------+\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check for entries that are non-date values\n",
    "capitalbikeshare_filtered.filter(~col(\"started_at\").rlike(\"^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}$\")).select(\"started_at\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3b79237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ride_id: string (nullable = true)\n",
      " |-- rideable_type: string (nullable = true)\n",
      " |-- started_at: string (nullable = true)\n",
      " |-- ended_at: string (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_id: float (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_id: float (nullable = true)\n",
      " |-- start_lat: float (nullable = true)\n",
      " |-- start_lng: float (nullable = true)\n",
      " |-- end_lat: float (nullable = true)\n",
      " |-- end_lng: float (nullable = true)\n",
      " |-- member_casual: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "capitalbikeshare_filtered.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637d3fde",
   "metadata": {},
   "source": [
    "We need to modify the date columns to be operable timestamp columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f4fc867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp\n",
    "\n",
    "# Rename the original date columns to indicate they are string representations\n",
    "capitalbikeshare_dateOperable = capitalbikeshare_filtered.withColumnRenamed(\"started_at\", \"Start_date_str\") \\\n",
    "                                            .withColumnRenamed(\"ended_at\", \"End_date_str\")\n",
    "\n",
    "# Convert the string date columns to timestamp data type with the original column names\n",
    "capitalbikeshare_dateOperable = capitalbikeshare_dateOperable.withColumn(\n",
    "    \"started_at\", to_timestamp(col(\"Start_date_str\"), \"yyyy-MM-dd HH:mm:ss\")\n",
    ").withColumn(\n",
    "    \"ended_at\", to_timestamp(col(\"End_date_str\"), \"yyyy-MM-dd HH:mm:ss\")\n",
    ")\n",
    "\n",
    "# Drop the original string date columns\n",
    "capitalbikeshare_dateOperable = capitalbikeshare_dateOperable.drop(\"Start_date_str\", \"End_date_str\")\n",
    "\n",
    "# The DataFrame now has timestamp columns with the original names for date-based operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[: int, ride_id: string, rideable_type: string, start_station_name: string, start_station_id: float, end_station_name: string, end_station_id: float, start_lat: float, start_lng: float, end_lat: float, end_lng: float, member_casual: string, started_at: timestamp, ended_at: timestamp]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitalbikeshare_filtered.unpersist()\n",
    "capitalbikeshare_dateOperable.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dad16913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>77A0F1B26D1597B1</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>Rhode Island &amp; Connecticut Ave NW</td>\n",
       "      <td>31239.0</td>\n",
       "      <td>12th &amp; L St NW</td>\n",
       "      <td>31251.0</td>\n",
       "      <td>38.905994</td>\n",
       "      <td>-77.039803</td>\n",
       "      <td>38.903820</td>\n",
       "      <td>-77.028397</td>\n",
       "      <td>casual</td>\n",
       "      <td>2020-04-25 17:28:39</td>\n",
       "      <td>2020-04-25 17:35:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8698F10128EA4F18</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>21st &amp; I St NW</td>\n",
       "      <td>31205.0</td>\n",
       "      <td>18th &amp; L St NW</td>\n",
       "      <td>31224.0</td>\n",
       "      <td>38.900711</td>\n",
       "      <td>-77.046448</td>\n",
       "      <td>38.903740</td>\n",
       "      <td>-77.042450</td>\n",
       "      <td>member</td>\n",
       "      <td>2020-04-06 07:54:59</td>\n",
       "      <td>2020-04-06 07:57:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AA07819DC0F58872</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>Connecticut Ave &amp; Tilden St NW</td>\n",
       "      <td>31313.0</td>\n",
       "      <td>Connecticut Ave &amp; Tilden St NW</td>\n",
       "      <td>31313.0</td>\n",
       "      <td>38.941139</td>\n",
       "      <td>-77.061974</td>\n",
       "      <td>38.941139</td>\n",
       "      <td>-77.061974</td>\n",
       "      <td>casual</td>\n",
       "      <td>2020-04-22 17:06:18</td>\n",
       "      <td>2020-04-22 18:08:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DA909BCA92EF85AB</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>7th &amp; E St SW</td>\n",
       "      <td>31294.0</td>\n",
       "      <td>7th &amp; E St SW</td>\n",
       "      <td>31294.0</td>\n",
       "      <td>38.883450</td>\n",
       "      <td>-77.021744</td>\n",
       "      <td>38.883450</td>\n",
       "      <td>-77.021744</td>\n",
       "      <td>casual</td>\n",
       "      <td>2020-04-16 15:22:40</td>\n",
       "      <td>2020-04-16 15:58:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B36F1E14D8C6757E</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>Potomac &amp; Pennsylvania Ave SE</td>\n",
       "      <td>31606.0</td>\n",
       "      <td>8th &amp; Eye St SE / Barracks Row</td>\n",
       "      <td>31608.0</td>\n",
       "      <td>38.880299</td>\n",
       "      <td>-76.986198</td>\n",
       "      <td>38.879200</td>\n",
       "      <td>-76.995300</td>\n",
       "      <td>member</td>\n",
       "      <td>2020-04-10 13:19:41</td>\n",
       "      <td>2020-04-10 13:23:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ride_id rideable_type                 start_station_name  \\\n",
       "0  0  77A0F1B26D1597B1   docked_bike  Rhode Island & Connecticut Ave NW   \n",
       "1  1  8698F10128EA4F18   docked_bike                     21st & I St NW   \n",
       "2  2  AA07819DC0F58872   docked_bike     Connecticut Ave & Tilden St NW   \n",
       "3  3  DA909BCA92EF85AB   docked_bike                      7th & E St SW   \n",
       "4  4  B36F1E14D8C6757E   docked_bike      Potomac & Pennsylvania Ave SE   \n",
       "\n",
       "   start_station_id                end_station_name  end_station_id  \\\n",
       "0           31239.0                  12th & L St NW         31251.0   \n",
       "1           31205.0                  18th & L St NW         31224.0   \n",
       "2           31313.0  Connecticut Ave & Tilden St NW         31313.0   \n",
       "3           31294.0                   7th & E St SW         31294.0   \n",
       "4           31606.0  8th & Eye St SE / Barracks Row         31608.0   \n",
       "\n",
       "   start_lat  start_lng    end_lat    end_lng member_casual  \\\n",
       "0  38.905994 -77.039803  38.903820 -77.028397        casual   \n",
       "1  38.900711 -77.046448  38.903740 -77.042450        member   \n",
       "2  38.941139 -77.061974  38.941139 -77.061974        casual   \n",
       "3  38.883450 -77.021744  38.883450 -77.021744        casual   \n",
       "4  38.880299 -76.986198  38.879200 -76.995300        member   \n",
       "\n",
       "           started_at            ended_at  \n",
       "0 2020-04-25 17:28:39 2020-04-25 17:35:04  \n",
       "1 2020-04-06 07:54:59 2020-04-06 07:57:24  \n",
       "2 2020-04-22 17:06:18 2020-04-22 18:08:32  \n",
       "3 2020-04-16 15:22:40 2020-04-16 15:58:37  \n",
       "4 2020-04-10 13:19:41 2020-04-10 13:23:05  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitalbikeshare_dateOperable.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a940358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column  has 0 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column ride_id has 0 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column rideable_type has 0 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column start_station_name has 680271 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column start_station_id has 680273 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column end_station_name has 753012 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column end_station_id has 753014 missing values\n",
      "Column start_lat has 10 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column start_lng has 10 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column end_lat has 22184 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column end_lng has 22184 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column member_casual has 0 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column started_at has 0 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:==========================================>             (13 + 4) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column ended_at has 0 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# For each column, select the column, perform a count of nulls, and then show the results\n",
    "for column in capitalbikeshare_dateOperable.columns:\n",
    "    missing_count = capitalbikeshare_dateOperable.filter(col(column).isNull()).count()\n",
    "    print(f\"Column {column} has {missing_count} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17d843c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|     Start date min|     Start date max|\n",
      "+-------------------+-------------------+\n",
      "|2020-04-01 00:25:48|2023-09-30 23:59:58|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:====================================>                   (11 + 6) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|       End date min|       End date max|\n",
      "+-------------------+-------------------+\n",
      "|2020-04-01 00:27:59|2023-10-05 02:00:19|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Find the minimum and maximum of the Start date (obviously it takes really long, \n",
    "# so I won't be using it after I've checked that it's correct).\n",
    "\n",
    "from pyspark.sql.functions import min, max\n",
    "\n",
    "# Find the minimum and maximum of the Start date\n",
    "start_date_range = capitalbikeshare_dateOperable.agg(\n",
    "    min(\"started_at\").alias(\"Start date min\"),\n",
    "    max(\"started_at\").alias(\"Start date max\")\n",
    ")\n",
    "\n",
    "# Find the minimum and maximum of the End date\n",
    "end_date_range = capitalbikeshare_dateOperable.agg(\n",
    "    min(\"ended_at\").alias(\"End date min\"),\n",
    "    max(\"ended_at\").alias(\"End date max\")\n",
    ")\n",
    "\n",
    "# Show the results\n",
    "start_date_range.show()\n",
    "end_date_range.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7b5564e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- : integer (nullable = true)\n",
      " |-- ride_id: string (nullable = true)\n",
      " |-- rideable_type: string (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_id: float (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_id: float (nullable = true)\n",
      " |-- start_lat: float (nullable = true)\n",
      " |-- start_lng: float (nullable = true)\n",
      " |-- end_lat: float (nullable = true)\n",
      " |-- end_lng: float (nullable = true)\n",
      " |-- member_casual: string (nullable = true)\n",
      " |-- started_at: timestamp (nullable = true)\n",
      " |-- ended_at: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Observe schema\n",
    "capitalbikeshare_dateOperable.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7117d7b8",
   "metadata": {},
   "source": [
    "### Weather Dataset Info\n",
    "\n",
    "https://www.visualcrossing.com/resources/documentation/weather-data/weather-data-documentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a7dcea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "weatherdata_raw = (spark.read\n",
    "                    .option(\"inferSchema\", \"true\")\n",
    "                    .option('header', 'true')\n",
    "                    .csv(\"hdfs://localhost:9000/datalake/raw/weather/weather\")\n",
    "                    .cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "880a39f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>datetime</th>\n",
       "      <th>tempmax</th>\n",
       "      <th>tempmin</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslikemax</th>\n",
       "      <th>feelslikemin</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>...</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>severerisk</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>moonphase</th>\n",
       "      <th>conditions</th>\n",
       "      <th>description</th>\n",
       "      <th>icon</th>\n",
       "      <th>stations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>washinton dc</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>25.9</td>\n",
       "      <td>31.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>26.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>70.6</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-01 05:46:51</td>\n",
       "      <td>2020-07-01 20:37:16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>Rain, Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day with rain.</td>\n",
       "      <td>rain</td>\n",
       "      <td>KDCA,72405013743,72403793728,F0198,KGAI,KADW,KDAA,AS365,72033493764,74594013705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>washinton dc</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>33.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>33.7</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>...</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-02 05:47:21</td>\n",
       "      <td>2020-07-02 20:37:08</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Becoming cloudy in the afternoon.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>KDCA,72405013743,72403793728,F0198,KGAI,KDAA,AS365,KADW,72033493764,74594013705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>washinton dc</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>35.5</td>\n",
       "      <td>24.1</td>\n",
       "      <td>30.3</td>\n",
       "      <td>37.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-03 05:47:52</td>\n",
       "      <td>2020-07-03 20:36:58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>KDCA,72405013743,72403793728,F0198,KADW,KDAA,74594013705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>washinton dc</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>33.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>29.2</td>\n",
       "      <td>35.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>30.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>58.3</td>\n",
       "      <td>...</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-04 05:48:24</td>\n",
       "      <td>2020-07-04 20:36:45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>Rain, Partially cloudy</td>\n",
       "      <td>Becoming cloudy in the afternoon with afternoon rain.</td>\n",
       "      <td>rain</td>\n",
       "      <td>KDCA,72405013743,72403793728,F0198,KADW,KDAA,AS365,74594013705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>washinton dc</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>33.6</td>\n",
       "      <td>24.2</td>\n",
       "      <td>28.4</td>\n",
       "      <td>38.7</td>\n",
       "      <td>24.2</td>\n",
       "      <td>30.7</td>\n",
       "      <td>22.4</td>\n",
       "      <td>71.3</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-05 05:48:58</td>\n",
       "      <td>2020-07-05 20:36:31</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>KDCA,72405013743,72403793728,F0198,KADW,KDAA,74594013705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name    datetime  tempmax  tempmin  temp  feelslikemax  \\\n",
       "0  washinton dc  2020-07-01     30.0     22.6  25.9          31.6   \n",
       "1  washinton dc  2020-07-02     33.3     22.0  27.8          33.7   \n",
       "2  washinton dc  2020-07-03     35.5     24.1  30.3          37.0   \n",
       "3  washinton dc  2020-07-04     33.6     25.3  29.2          35.6   \n",
       "4  washinton dc  2020-07-05     33.6     24.2  28.4          38.7   \n",
       "\n",
       "   feelslikemin  feelslike   dew  humidity  ...  solarenergy  uvindex  \\\n",
       "0          22.6       26.5  20.0      70.6  ...          6.0        4   \n",
       "1          22.0       28.1  18.0      57.9  ...          6.2        4   \n",
       "2          24.1       31.0  18.0      49.2  ...          7.1        6   \n",
       "3          25.3       30.7  20.0      58.3  ...          6.2        4   \n",
       "4          24.2       30.7  22.4      71.3  ...          6.1        4   \n",
       "\n",
       "   severerisk             sunrise              sunset  moonphase  \\\n",
       "0         NaN 2020-07-01 05:46:51 2020-07-01 20:37:16       0.37   \n",
       "1         NaN 2020-07-02 05:47:21 2020-07-02 20:37:08       0.41   \n",
       "2         NaN 2020-07-03 05:47:52 2020-07-03 20:36:58       0.45   \n",
       "3         NaN 2020-07-04 05:48:24 2020-07-04 20:36:45       0.48   \n",
       "4         NaN 2020-07-05 05:48:58 2020-07-05 20:36:31       0.50   \n",
       "\n",
       "               conditions  \\\n",
       "0  Rain, Partially cloudy   \n",
       "1        Partially cloudy   \n",
       "2        Partially cloudy   \n",
       "3  Rain, Partially cloudy   \n",
       "4        Partially cloudy   \n",
       "\n",
       "                                             description               icon  \\\n",
       "0            Partly cloudy throughout the day with rain.               rain   \n",
       "1                      Becoming cloudy in the afternoon.  partly-cloudy-day   \n",
       "2                      Partly cloudy throughout the day.  partly-cloudy-day   \n",
       "3  Becoming cloudy in the afternoon with afternoon rain.               rain   \n",
       "4                      Partly cloudy throughout the day.  partly-cloudy-day   \n",
       "\n",
       "                                                                          stations  \n",
       "0  KDCA,72405013743,72403793728,F0198,KGAI,KADW,KDAA,AS365,72033493764,74594013705  \n",
       "1  KDCA,72405013743,72403793728,F0198,KGAI,KDAA,AS365,KADW,72033493764,74594013705  \n",
       "2                         KDCA,72405013743,72403793728,F0198,KADW,KDAA,74594013705  \n",
       "3                   KDCA,72405013743,72403793728,F0198,KADW,KDAA,AS365,74594013705  \n",
       "4                         KDCA,72405013743,72403793728,F0198,KADW,KDAA,74594013705  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherdata_raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7d8bc03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- datetime: string (nullable = true)\n",
      " |-- tempmax: double (nullable = true)\n",
      " |-- tempmin: double (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- feelslikemax: double (nullable = true)\n",
      " |-- feelslikemin: double (nullable = true)\n",
      " |-- feelslike: double (nullable = true)\n",
      " |-- dew: double (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- precip: double (nullable = true)\n",
      " |-- precipprob: integer (nullable = true)\n",
      " |-- precipcover: double (nullable = true)\n",
      " |-- preciptype: string (nullable = true)\n",
      " |-- snow: double (nullable = true)\n",
      " |-- snowdepth: double (nullable = true)\n",
      " |-- windgust: double (nullable = true)\n",
      " |-- windspeed: double (nullable = true)\n",
      " |-- winddir: double (nullable = true)\n",
      " |-- sealevelpressure: double (nullable = true)\n",
      " |-- cloudcover: double (nullable = true)\n",
      " |-- visibility: double (nullable = true)\n",
      " |-- solarradiation: double (nullable = true)\n",
      " |-- solarenergy: double (nullable = true)\n",
      " |-- uvindex: integer (nullable = true)\n",
      " |-- severerisk: integer (nullable = true)\n",
      " |-- sunrise: timestamp (nullable = true)\n",
      " |-- sunset: timestamp (nullable = true)\n",
      " |-- moonphase: double (nullable = true)\n",
      " |-- conditions: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- icon: string (nullable = true)\n",
      " |-- stations: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Observe schema\n",
    "weatherdata_raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627328e4",
   "metadata": {},
   "source": [
    "Analyzing columns PRELIMINARILY:\n",
    "\n",
    "root\n",
    " |-- name: string (nullable = true) <--------------------- IRRELEVANT\n",
    " \n",
    " |-- datetime: string (nullable = true) <--------------------- NOT TIMESTAMP\n",
    " \n",
    " |-- tempmax: double (nullable = true) <--------------------- POSSIBLE REDUNDANCIES GROUP 1\n",
    " \n",
    " |-- tempmin: double (nullable = true) <--------------------- POSSIBLE REDUNDANCIES GROUP 1\n",
    " \n",
    " |-- temp: double (nullable = true) <--------------------- POSSIBLE REDUNDANCIES GROUP 1\n",
    " \n",
    " |-- feelslikemax: double (nullable = true) <--------------------- POSSIBLE REDUNDANCIES GROUP 2\n",
    " \n",
    " |-- feelslikemin: double (nullable = true) <--------------------- POSSIBLE REDUNDANCIES GROUP 2\n",
    " \n",
    " |-- feelslike: double (nullable = true) <--------------------- POSSIBLE REDUNDANCIES GROUP 2\n",
    " \n",
    " |-- dew: double (nullable = true)\n",
    " \n",
    " |-- humidity: double (nullable = true) <--------------------- POSSIBLE REDUNDANCIES GROUP 3\n",
    " \n",
    " |-- precip: double (nullable = true) <--------------------- POSSIBLE REDUNDANCIES GROUP 3\n",
    " \n",
    " |-- precipprob: integer (nullable = true) <--------------------- POSSIBLE REDUNDANCIES GROUP 3\n",
    " \n",
    " |-- precipcover: double (nullable = true) <--------------------- POSSIBLE REDUNDANCIES GROUP 3\n",
    " \n",
    " |-- preciptype: string (nullable = true)\n",
    " \n",
    " |-- snow: double (nullable = true)\n",
    " \n",
    " |-- snowdepth: double (nullable = true)\n",
    " \n",
    " |-- windgust: double (nullable = true) <--------------------- POSSIBLE REDUNDANCIES GROUP 4\n",
    " \n",
    " |-- windspeed: double (nullable = true) <--------------------- POSSIBLE REDUNDANCIES GROUP 4\n",
    " \n",
    " |-- winddir: double (nullable = true)\n",
    " \n",
    " |-- sealevelpressure: double (nullable = true)\n",
    " \n",
    " |-- cloudcover: double (nullable = true)\n",
    " \n",
    " |-- visibility: double (nullable = true)\n",
    " \n",
    " |-- solarradiation: double (nullable = true) <--------------------- POSSIBLE REDUNDANCIES GROUP 5\n",
    " \n",
    " |-- solarenergy: double (nullable = true) <--------------------- POSSIBLE REDUNDANCIES GROUP 5\n",
    " \n",
    " |-- uvindex: integer (nullable = true)\n",
    " \n",
    " |-- severerisk: integer (nullable = true)\n",
    " \n",
    " |-- sunrise: timestamp (nullable = true) <--------------------- EXTRACT TO 'sunlight_hours'\n",
    " \n",
    " |-- sunset: timestamp (nullable = true) <--------------------- EXTRACT TO 'sunlight_hours'\n",
    " \n",
    " |-- moonphase: double (nullable = true)\n",
    " \n",
    " |-- conditions: string (nullable = true) <--------------------- REDUNDANT & IMPRACTICAL\n",
    " \n",
    " |-- description: string (nullable = true) <--------------------- REDUNDANT & IMPRACTICAL\n",
    " \n",
    " |-- icon: string (nullable = true) <--------------------- REDUNDANT & IMPRACTICAL\n",
    " \n",
    " |-- stations: string (nullable = true) <--------------------- IRRELEVANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60e670d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of capitalbikeshare_dateOperable is: (11246784, 14)\n",
      "The shape of weatherdata_raw is: (2133, 33)\n"
     ]
    }
   ],
   "source": [
    "# For the capitalbikeshare_raw DataFrame\n",
    "capitalbikeshare_row_count = capitalbikeshare_dateOperable.count()\n",
    "capitalbikeshare_column_count = len(capitalbikeshare_dateOperable.columns)\n",
    "print(f\"The shape of capitalbikeshare_dateOperable is: ({capitalbikeshare_row_count}, {capitalbikeshare_column_count})\")\n",
    "\n",
    "# For the weatherdata_raw DataFrame\n",
    "weatherdata_row_count = weatherdata_raw.count()\n",
    "weatherdata_column_count = len(weatherdata_raw.columns)\n",
    "print(f\"The shape of weatherdata_raw is: ({weatherdata_row_count}, {weatherdata_column_count})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71176223",
   "metadata": {},
   "source": [
    "#### Comment on Dataset Size\n",
    "\n",
    "- **capitalbikeshare_raw** has 22,108,947 rows and 9 columns, which is quite sizable. Operations on this DataFrame, especially those that require a full pass over the data like .count(), .show(), or any kind of groupBy/aggregation, will take a noticeable amount of time to complete.\n",
    "- **weatherdata_raw** has 2,133 rows and 33 columns, which is relatively small. Operations on this DataFrame should be much faster and are generally reasonable to perform without needing to sample or otherwise optimize for performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e459dc",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f68fc8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- datetime: timestamp (nullable = true)\n",
      " |-- tempmax: double (nullable = true)\n",
      " |-- tempmin: double (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- feelslikemax: double (nullable = true)\n",
      " |-- feelslikemin: double (nullable = true)\n",
      " |-- feelslike: double (nullable = true)\n",
      " |-- dew: double (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- precip: double (nullable = true)\n",
      " |-- precipprob: integer (nullable = true)\n",
      " |-- precipcover: double (nullable = true)\n",
      " |-- preciptype: string (nullable = true)\n",
      " |-- snow: double (nullable = true)\n",
      " |-- snowdepth: double (nullable = true)\n",
      " |-- windgust: double (nullable = true)\n",
      " |-- windspeed: double (nullable = true)\n",
      " |-- winddir: double (nullable = true)\n",
      " |-- sealevelpressure: double (nullable = true)\n",
      " |-- cloudcover: double (nullable = true)\n",
      " |-- visibility: double (nullable = true)\n",
      " |-- solarradiation: double (nullable = true)\n",
      " |-- solarenergy: double (nullable = true)\n",
      " |-- uvindex: integer (nullable = true)\n",
      " |-- severerisk: integer (nullable = true)\n",
      " |-- sunrise: timestamp (nullable = true)\n",
      " |-- sunset: timestamp (nullable = true)\n",
      " |-- moonphase: double (nullable = true)\n",
      " |-- conditions: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- icon: string (nullable = true)\n",
      " |-- stations: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "# Convert the 'datetime' column to timestamp data type\n",
    "weatherdata_raw = weatherdata_raw.withColumn(\n",
    "    \"datetime\", to_timestamp(\"datetime\", \"yyyy-MM-dd\")\n",
    ")\n",
    "\n",
    "# Now the 'datetime' column is in timestamp format and ready for joining with the other dataset\n",
    "\n",
    "\n",
    "weatherdata_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57d2f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, round\n",
    "\n",
    "# Calculate 'sunlight_hours' by finding the difference between 'sunset' and 'sunrise', and convert to hours\n",
    "weatherdata_raw = weatherdata_raw.withColumn(\n",
    "    \"sunlight_hours\",\n",
    "    round((unix_timestamp(\"sunset\") - unix_timestamp(\"sunrise\")) / 3600.0, 2)\n",
    ")\n",
    "\n",
    "# The 'sunlight_hours' column will now contain the duration of sunlight in hours, rounded to two decimal places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce835368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>datetime</th>\n",
       "      <th>tempmax</th>\n",
       "      <th>tempmin</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslikemax</th>\n",
       "      <th>feelslikemin</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>...</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>severerisk</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>moonphase</th>\n",
       "      <th>conditions</th>\n",
       "      <th>description</th>\n",
       "      <th>icon</th>\n",
       "      <th>stations</th>\n",
       "      <th>sunlight_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>washinton dc</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>25.9</td>\n",
       "      <td>31.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>26.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>70.6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-01 05:46:51</td>\n",
       "      <td>2020-07-01 20:37:16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>Rain, Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day with rain.</td>\n",
       "      <td>rain</td>\n",
       "      <td>KDCA,72405013743,72403793728,F0198,KGAI,KADW,KDAA,AS365,72033493764,74594013705</td>\n",
       "      <td>14.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>washinton dc</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>33.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>33.7</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-02 05:47:21</td>\n",
       "      <td>2020-07-02 20:37:08</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Becoming cloudy in the afternoon.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>KDCA,72405013743,72403793728,F0198,KGAI,KDAA,AS365,KADW,72033493764,74594013705</td>\n",
       "      <td>14.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>washinton dc</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>35.5</td>\n",
       "      <td>24.1</td>\n",
       "      <td>30.3</td>\n",
       "      <td>37.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-03 05:47:52</td>\n",
       "      <td>2020-07-03 20:36:58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>KDCA,72405013743,72403793728,F0198,KADW,KDAA,74594013705</td>\n",
       "      <td>14.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>washinton dc</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>33.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>29.2</td>\n",
       "      <td>35.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>30.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>58.3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-04 05:48:24</td>\n",
       "      <td>2020-07-04 20:36:45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>Rain, Partially cloudy</td>\n",
       "      <td>Becoming cloudy in the afternoon with afternoon rain.</td>\n",
       "      <td>rain</td>\n",
       "      <td>KDCA,72405013743,72403793728,F0198,KADW,KDAA,AS365,74594013705</td>\n",
       "      <td>14.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>washinton dc</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>33.6</td>\n",
       "      <td>24.2</td>\n",
       "      <td>28.4</td>\n",
       "      <td>38.7</td>\n",
       "      <td>24.2</td>\n",
       "      <td>30.7</td>\n",
       "      <td>22.4</td>\n",
       "      <td>71.3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-05 05:48:58</td>\n",
       "      <td>2020-07-05 20:36:31</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>KDCA,72405013743,72403793728,F0198,KADW,KDAA,74594013705</td>\n",
       "      <td>14.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name   datetime  tempmax  tempmin  temp  feelslikemax  \\\n",
       "0  washinton dc 2020-07-01     30.0     22.6  25.9          31.6   \n",
       "1  washinton dc 2020-07-02     33.3     22.0  27.8          33.7   \n",
       "2  washinton dc 2020-07-03     35.5     24.1  30.3          37.0   \n",
       "3  washinton dc 2020-07-04     33.6     25.3  29.2          35.6   \n",
       "4  washinton dc 2020-07-05     33.6     24.2  28.4          38.7   \n",
       "\n",
       "   feelslikemin  feelslike   dew  humidity  ...  uvindex  severerisk  \\\n",
       "0          22.6       26.5  20.0      70.6  ...        4         NaN   \n",
       "1          22.0       28.1  18.0      57.9  ...        4         NaN   \n",
       "2          24.1       31.0  18.0      49.2  ...        6         NaN   \n",
       "3          25.3       30.7  20.0      58.3  ...        4         NaN   \n",
       "4          24.2       30.7  22.4      71.3  ...        4         NaN   \n",
       "\n",
       "              sunrise              sunset  moonphase              conditions  \\\n",
       "0 2020-07-01 05:46:51 2020-07-01 20:37:16       0.37  Rain, Partially cloudy   \n",
       "1 2020-07-02 05:47:21 2020-07-02 20:37:08       0.41        Partially cloudy   \n",
       "2 2020-07-03 05:47:52 2020-07-03 20:36:58       0.45        Partially cloudy   \n",
       "3 2020-07-04 05:48:24 2020-07-04 20:36:45       0.48  Rain, Partially cloudy   \n",
       "4 2020-07-05 05:48:58 2020-07-05 20:36:31       0.50        Partially cloudy   \n",
       "\n",
       "                                             description               icon  \\\n",
       "0            Partly cloudy throughout the day with rain.               rain   \n",
       "1                      Becoming cloudy in the afternoon.  partly-cloudy-day   \n",
       "2                      Partly cloudy throughout the day.  partly-cloudy-day   \n",
       "3  Becoming cloudy in the afternoon with afternoon rain.               rain   \n",
       "4                      Partly cloudy throughout the day.  partly-cloudy-day   \n",
       "\n",
       "                                                                          stations  \\\n",
       "0  KDCA,72405013743,72403793728,F0198,KGAI,KADW,KDAA,AS365,72033493764,74594013705   \n",
       "1  KDCA,72405013743,72403793728,F0198,KGAI,KDAA,AS365,KADW,72033493764,74594013705   \n",
       "2                         KDCA,72405013743,72403793728,F0198,KADW,KDAA,74594013705   \n",
       "3                   KDCA,72405013743,72403793728,F0198,KADW,KDAA,AS365,74594013705   \n",
       "4                         KDCA,72405013743,72403793728,F0198,KADW,KDAA,74594013705   \n",
       "\n",
       "   sunlight_hours  \n",
       "0           14.84  \n",
       "1           14.83  \n",
       "2           14.82  \n",
       "3           14.81  \n",
       "4           14.79  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherdata_raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4257f529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['washinton dc']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining all unique values in 'name' column (knowing they can't be many...), to ensure we should drop it.\n",
    "unique_names = weatherdata_raw.select('name').distinct().collect()\n",
    "\n",
    "# If there are only 1 or 2 unique values, this will be quick\n",
    "unique_values = [row['name'] for row in unique_names]\n",
    "unique_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5458e4fa",
   "metadata": {},
   "source": [
    "Explore missing values for weatherdata_raw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed8d8f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cloudcover</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conditions</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datetime</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>description</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dew</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feelslike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feelslikemax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feelslikemin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humidity</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>icon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>moonphase</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>name</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>precip</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>precipcover</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>precipprob</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>preciptype</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>53.633380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sealevelpressure</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>severerisk</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>68.917018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>snow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>snowdepth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>solarenergy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>solarradiation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>stations</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sunlight_hours</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sunrise</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sunset</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>temp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tempmax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tempmin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>uvindex</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>visibility</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>winddir</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>windgust</td>\n",
       "      <td>555.0</td>\n",
       "      <td>26.019691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>windspeed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Column  Missing Count  Missing Percent\n",
       "0         cloudcover            0.0         0.000000\n",
       "1         conditions            0.0         0.000000\n",
       "2           datetime            0.0         0.000000\n",
       "3        description            0.0         0.000000\n",
       "4                dew            0.0         0.000000\n",
       "5          feelslike            0.0         0.000000\n",
       "6       feelslikemax            0.0         0.000000\n",
       "7       feelslikemin            0.0         0.000000\n",
       "8           humidity            0.0         0.000000\n",
       "9               icon            0.0         0.000000\n",
       "10         moonphase            0.0         0.000000\n",
       "11              name            0.0         0.000000\n",
       "12            precip            0.0         0.000000\n",
       "13       precipcover            0.0         0.000000\n",
       "14        precipprob            0.0         0.000000\n",
       "15        preciptype         1144.0        53.633380\n",
       "16  sealevelpressure            0.0         0.000000\n",
       "17        severerisk         1470.0        68.917018\n",
       "18              snow            0.0         0.000000\n",
       "19         snowdepth            0.0         0.000000\n",
       "20       solarenergy            0.0         0.000000\n",
       "21    solarradiation            0.0         0.000000\n",
       "22          stations            0.0         0.000000\n",
       "23    sunlight_hours            0.0         0.000000\n",
       "24           sunrise            0.0         0.000000\n",
       "25            sunset            0.0         0.000000\n",
       "26              temp            0.0         0.000000\n",
       "27           tempmax            0.0         0.000000\n",
       "28           tempmin            0.0         0.000000\n",
       "29           uvindex            0.0         0.000000\n",
       "30        visibility            0.0         0.000000\n",
       "31           winddir            0.0         0.000000\n",
       "32          windgust          555.0        26.019691\n",
       "33         windspeed            0.0         0.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, when, isnan, lit\n",
    "from pyspark.sql.types import DoubleType, FloatType\n",
    "\n",
    "# Function to calculate missing values\n",
    "def calculate_missing_values(df):\n",
    "    total_rows = df.count()\n",
    "    agg_exprs = []\n",
    "    for c in df.columns:\n",
    "        # For numerical columns, check for both null and NaN\n",
    "        if isinstance(df.schema[c].dataType, (DoubleType, FloatType)):\n",
    "            agg_exprs.append(count(when(col(c).isNull() | isnan(col(c)), c)).alias(c + '_count'))\n",
    "            agg_exprs.append((count(when(col(c).isNull() | isnan(col(c)), c)) / total_rows * 100).alias(c + '_percent'))\n",
    "        # For non-numerical columns, only check for null\n",
    "        else:\n",
    "            agg_exprs.append(count(when(col(c).isNull(), c)).alias(c + '_count'))\n",
    "            agg_exprs.append((count(when(col(c).isNull(), c)) / total_rows * 100).alias(c + '_percent'))\n",
    "    return df.agg(*agg_exprs)\n",
    "\n",
    "# Use the function to calculate missing values on the DataFrame\n",
    "missing_values_df = calculate_missing_values(weatherdata_raw)\n",
    "\n",
    "# Convert to Pandas DataFrame for better formatting\n",
    "missing_values_pandas = missing_values_df.toPandas()\n",
    "\n",
    "# Transpose the DataFrame to have column names as the row index\n",
    "missing_values_pandas = missing_values_pandas.transpose().reset_index()\n",
    "\n",
    "# Split the 'index' column to separate the column names and the '_count' or '_percent' suffix\n",
    "missing_values_pandas[['Column', 'Metric']] = missing_values_pandas['index'].str.rsplit('_', n=1, expand=True)\n",
    "\n",
    "# Pivot the DataFrame to get the 'Missing Count' and 'Missing Percent' as separate columns\n",
    "missing_values_pandas = missing_values_pandas.pivot(index='Column', columns='Metric', values=0)\n",
    "\n",
    "# Reset the index to turn 'Column' back into a regular column\n",
    "missing_values_pandas.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns for clarity\n",
    "missing_values_pandas.columns = ['Column', 'Missing Count', 'Missing Percent']\n",
    "\n",
    "# Display the DataFrame\n",
    "missing_values_pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f790ace5",
   "metadata": {},
   "source": [
    "Drop the irrelevant columns and those with too many missing values (taking in to account the amount of other related weather variables):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88b9ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weatherdata_clean = weatherdata_raw.drop('name', 'conditions', 'description', 'icon','preciptype','severerisk','windgust','stations')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, datetime: timestamp, tempmax: double, tempmin: double, temp: double, feelslikemax: double, feelslikemin: double, feelslike: double, dew: double, humidity: double, precip: double, precipprob: int, precipcover: double, preciptype: string, snow: double, snowdepth: double, windgust: double, windspeed: double, winddir: double, sealevelpressure: double, cloudcover: double, visibility: double, solarradiation: double, solarenergy: double, uvindex: int, severerisk: int, sunrise: timestamp, sunset: timestamp, moonphase: double, conditions: string, description: string, icon: string, stations: string, sunlight_hours: double]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherdata_raw.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69fa7263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>tempmax</th>\n",
       "      <th>tempmin</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslikemax</th>\n",
       "      <th>feelslikemin</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precip</th>\n",
       "      <th>...</th>\n",
       "      <th>sealevelpressure</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>solarradiation</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>moonphase</th>\n",
       "      <th>sunlight_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>25.9</td>\n",
       "      <td>31.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>26.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>70.6</td>\n",
       "      <td>3.133</td>\n",
       "      <td>...</td>\n",
       "      <td>1011.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>71.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-07-01 05:46:51</td>\n",
       "      <td>2020-07-01 20:37:16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>14.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>33.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>33.7</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>36.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>73.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-07-02 05:47:21</td>\n",
       "      <td>2020-07-02 20:37:08</td>\n",
       "      <td>0.41</td>\n",
       "      <td>14.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>35.5</td>\n",
       "      <td>24.1</td>\n",
       "      <td>30.3</td>\n",
       "      <td>37.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1011.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-07-03 05:47:52</td>\n",
       "      <td>2020-07-03 20:36:58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>14.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>33.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>29.2</td>\n",
       "      <td>35.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>30.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>58.3</td>\n",
       "      <td>0.537</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.7</td>\n",
       "      <td>40.9</td>\n",
       "      <td>15.7</td>\n",
       "      <td>73.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-07-04 05:48:24</td>\n",
       "      <td>2020-07-04 20:36:45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>14.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>33.6</td>\n",
       "      <td>24.2</td>\n",
       "      <td>28.4</td>\n",
       "      <td>38.7</td>\n",
       "      <td>24.2</td>\n",
       "      <td>30.7</td>\n",
       "      <td>22.4</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1014.8</td>\n",
       "      <td>44.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>69.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-07-05 05:48:58</td>\n",
       "      <td>2020-07-05 20:36:31</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime  tempmax  tempmin  temp  feelslikemax  feelslikemin  feelslike  \\\n",
       "0 2020-07-01     30.0     22.6  25.9          31.6          22.6       26.5   \n",
       "1 2020-07-02     33.3     22.0  27.8          33.7          22.0       28.1   \n",
       "2 2020-07-03     35.5     24.1  30.3          37.0          24.1       31.0   \n",
       "3 2020-07-04     33.6     25.3  29.2          35.6          25.3       30.7   \n",
       "4 2020-07-05     33.6     24.2  28.4          38.7          24.2       30.7   \n",
       "\n",
       "    dew  humidity  precip  ...  sealevelpressure  cloudcover  visibility  \\\n",
       "0  20.0      70.6   3.133  ...            1011.5        54.0        16.0   \n",
       "1  18.0      57.9   0.000  ...            1012.0        36.9        16.0   \n",
       "2  18.0      49.2   0.000  ...            1011.7        20.4        16.0   \n",
       "3  20.0      58.3   0.537  ...            1012.7        40.9        15.7   \n",
       "4  22.4      71.3   0.000  ...            1014.8        44.3        13.5   \n",
       "\n",
       "   solarradiation  solarenergy  uvindex             sunrise  \\\n",
       "0            71.3          6.0        4 2020-07-01 05:46:51   \n",
       "1            73.5          6.2        4 2020-07-02 05:47:21   \n",
       "2            84.0          7.1        6 2020-07-03 05:47:52   \n",
       "3            73.0          6.2        4 2020-07-04 05:48:24   \n",
       "4            69.9          6.1        4 2020-07-05 05:48:58   \n",
       "\n",
       "               sunset  moonphase  sunlight_hours  \n",
       "0 2020-07-01 20:37:16       0.37           14.84  \n",
       "1 2020-07-02 20:37:08       0.41           14.83  \n",
       "2 2020-07-03 20:36:58       0.45           14.82  \n",
       "3 2020-07-04 20:36:45       0.48           14.81  \n",
       "4 2020-07-05 20:36:31       0.50           14.79  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherdata_clean.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify no missing values for cleaned dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed9d8692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cloudcover</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datetime</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dew</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feelslike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feelslikemax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feelslikemin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>humidity</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>moonphase</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>precip</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>precipcover</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>precipprob</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sealevelpressure</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>snow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>snowdepth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>solarenergy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>solarradiation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sunlight_hours</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sunrise</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sunset</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>temp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tempmax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tempmin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>uvindex</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>visibility</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>winddir</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>windspeed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Column  Missing Count  Missing Percent\n",
       "0         cloudcover            0.0              0.0\n",
       "1           datetime            0.0              0.0\n",
       "2                dew            0.0              0.0\n",
       "3          feelslike            0.0              0.0\n",
       "4       feelslikemax            0.0              0.0\n",
       "5       feelslikemin            0.0              0.0\n",
       "6           humidity            0.0              0.0\n",
       "7          moonphase            0.0              0.0\n",
       "8             precip            0.0              0.0\n",
       "9        precipcover            0.0              0.0\n",
       "10        precipprob            0.0              0.0\n",
       "11  sealevelpressure            0.0              0.0\n",
       "12              snow            0.0              0.0\n",
       "13         snowdepth            0.0              0.0\n",
       "14       solarenergy            0.0              0.0\n",
       "15    solarradiation            0.0              0.0\n",
       "16    sunlight_hours            0.0              0.0\n",
       "17           sunrise            0.0              0.0\n",
       "18            sunset            0.0              0.0\n",
       "19              temp            0.0              0.0\n",
       "20           tempmax            0.0              0.0\n",
       "21           tempmin            0.0              0.0\n",
       "22           uvindex            0.0              0.0\n",
       "23        visibility            0.0              0.0\n",
       "24           winddir            0.0              0.0\n",
       "25         windspeed            0.0              0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the function to verify missing values on the cleaned DataFrame ('wd_c' stands for 'weatherdata_clean')\n",
    "missing_values_wd_c = calculate_missing_values(weatherdata_clean)\n",
    "\n",
    "# Convert to Pandas DataFrame for better formatting\n",
    "missing_values_wd_c_pandas = missing_values_wd_c.toPandas()\n",
    "\n",
    "# Transpose the DataFrame to have column names as the row index\n",
    "missing_values_wd_c_pandas = missing_values_wd_c_pandas.transpose().reset_index()\n",
    "\n",
    "# Split the 'index' column to separate the column names and the '_count' or '_percent' suffix\n",
    "missing_values_wd_c_pandas[['Column', 'Metric']] = missing_values_wd_c_pandas['index'].str.rsplit('_', n=1, expand=True)\n",
    "\n",
    "# Pivot the DataFrame to get the 'Missing Count' and 'Missing Percent' as separate columns\n",
    "missing_values_wd_c_pandas = missing_values_wd_c_pandas.pivot(index='Column', columns='Metric', values=0)\n",
    "\n",
    "# Reset the index to turn 'Column' back into a regular column\n",
    "missing_values_wd_c_pandas.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns for clarity\n",
    "missing_values_wd_c_pandas.columns = ['Column', 'Missing Count', 'Missing Percent']\n",
    "\n",
    "# Display the DataFrame\n",
    "missing_values_wd_c_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac2c49e",
   "metadata": {},
   "source": [
    "Explore missing values for capitalbikeshare_dateOperable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "288219d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_count</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ride_id_count</th>\n",
       "      <td>ride_id</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rideable_type_count</th>\n",
       "      <td>rideable_type</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_station_name_count</th>\n",
       "      <td>start_station_name</td>\n",
       "      <td>680271</td>\n",
       "      <td>6.05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_station_id_count</th>\n",
       "      <td>start_station_id</td>\n",
       "      <td>680273</td>\n",
       "      <td>6.05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_station_name_count</th>\n",
       "      <td>end_station_name</td>\n",
       "      <td>753012</td>\n",
       "      <td>6.70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_station_id_count</th>\n",
       "      <td>end_station_id</td>\n",
       "      <td>753014</td>\n",
       "      <td>6.70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_lat_count</th>\n",
       "      <td>start_lat</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_lng_count</th>\n",
       "      <td>start_lng</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_lat_count</th>\n",
       "      <td>end_lat</td>\n",
       "      <td>22184</td>\n",
       "      <td>0.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_lng_count</th>\n",
       "      <td>end_lng</td>\n",
       "      <td>22184</td>\n",
       "      <td>0.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>member_casual_count</th>\n",
       "      <td>member_casual</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>started_at_count</th>\n",
       "      <td>started_at</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ended_at_count</th>\n",
       "      <td>ended_at</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Column  Missing Count Missing Percent\n",
       "_count                                                    0           0.00%\n",
       "ride_id_count                        ride_id              0           0.00%\n",
       "rideable_type_count            rideable_type              0           0.00%\n",
       "start_station_name_count  start_station_name         680271           6.05%\n",
       "start_station_id_count      start_station_id         680273           6.05%\n",
       "end_station_name_count      end_station_name         753012           6.70%\n",
       "end_station_id_count          end_station_id         753014           6.70%\n",
       "start_lat_count                    start_lat             10           0.00%\n",
       "start_lng_count                    start_lng             10           0.00%\n",
       "end_lat_count                        end_lat          22184           0.20%\n",
       "end_lng_count                        end_lng          22184           0.20%\n",
       "member_casual_count            member_casual              0           0.00%\n",
       "started_at_count                  started_at              0           0.00%\n",
       "ended_at_count                      ended_at              0           0.00%"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType, FloatType\n",
    "from pyspark.sql.functions import isnan, when\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"missing_values\").getOrCreate()\n",
    "\n",
    "# Function to calculate missing values for each column\n",
    "def calculate_missing_values(df):\n",
    "    total_rows = df.count()\n",
    "    agg_exprs_counts = [\n",
    "        count(when(col(c).isNull(), c)).alias(c + '_count')\n",
    "        for c in df.columns\n",
    "    ]\n",
    "    agg_exprs_percent = [\n",
    "        (count(when(col(c).isNull(), c)) / total_rows * 100).alias(c + '_percent')\n",
    "        for c in df.columns\n",
    "    ]\n",
    "    return df.agg(*agg_exprs_counts + agg_exprs_percent)\n",
    "\n",
    "# Use the function to calculate missing values on the DataFrame\n",
    "missing_values_cbs_r = calculate_missing_values(capitalbikeshare_dateOperable)\n",
    "\n",
    "# Convert to Pandas DataFrame for better formatting\n",
    "missing_values_cbs_r_pandas = missing_values_cbs_r.toPandas()\n",
    "\n",
    "# Prepare the data for the desired output format\n",
    "missing_counts_cbs_r_final = pd.DataFrame({\n",
    "    'Column': [c.replace('_count', '') for c in missing_values_cbs_r_pandas.columns[:len(capitalbikeshare_dateOperable.columns)]],\n",
    "    'Missing Count': missing_values_cbs_r_pandas.iloc[0, :len(capitalbikeshare_dateOperable.columns)].astype(int),\n",
    "    'Missing Percent': missing_values_cbs_r_pandas.iloc[0, len(capitalbikeshare_dateOperable.columns):].values\n",
    "})\n",
    "\n",
    "# Format the 'Missing Percent' column to show as a percentage with two decimal places\n",
    "missing_counts_cbs_r_final['Missing Percent'] = missing_counts_cbs_r_final['Missing Percent'].map(lambda x: '{:.2f}%'.format(x))\n",
    "\n",
    "missing_counts_cbs_r_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop irrelevant columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with missing values\n",
    "columns_with_missing_values = ['start_station_name', 'end_station_name', 'start_lat', 'start_lng', 'end_lat', 'end_lng']\n",
    "\n",
    "# Drop rows with missing values in these columns\n",
    "capitalbikeshare_dropped_cols = capitalbikeshare_dateOperable.dropna(subset=columns_with_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[: int, ride_id: string, rideable_type: string, start_station_name: string, start_station_id: float, end_station_name: string, end_station_id: float, start_lat: float, start_lng: float, end_lat: float, end_lng: float, member_casual: string, started_at: timestamp, ended_at: timestamp]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitalbikeshare_dateOperable.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- : integer (nullable = true)\n",
      " |-- ride_id: string (nullable = true)\n",
      " |-- rideable_type: string (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_id: float (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_id: float (nullable = true)\n",
      " |-- start_lat: float (nullable = true)\n",
      " |-- start_lng: float (nullable = true)\n",
      " |-- end_lat: float (nullable = true)\n",
      " |-- end_lng: float (nullable = true)\n",
      " |-- member_casual: string (nullable = true)\n",
      " |-- started_at: timestamp (nullable = true)\n",
      " |-- ended_at: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "capitalbikeshare_dropped_cols.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all rows that contain missing values, as they are relatively few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:=================================================>      (15 + 2) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Drop all rows that contain missing values from the 'capitalbikeshare_dropped_cols' DataFrame\n",
    "capitalbikeshare_clean = capitalbikeshare_dropped_cols.dropna()\n",
    "\n",
    "# Count the number of rows in both DataFrames\n",
    "rows_cbs_dateOperable_count = capitalbikeshare_dropped_cols.count()\n",
    "rows_cbs_clean_count = capitalbikeshare_clean.count()\n",
    "\n",
    "# Calculate the number and percentage of rows that were dropped\n",
    "num_rows_dropped = rows_cbs_dateOperable_count - rows_cbs_clean_count\n",
    "percent_dropped = (float(num_rows_dropped) / rows_cbs_dateOperable_count) * 100\n",
    "\n",
    "# Print the number and percentage of rows that were dropped\n",
    "print(num_rows_dropped)\n",
    "print(percent_dropped)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify no more missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_count</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ride_id_count</th>\n",
       "      <td>ride_id</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rideable_type_count</th>\n",
       "      <td>rideable_type</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_station_name_count</th>\n",
       "      <td>start_station_name</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_station_id_count</th>\n",
       "      <td>start_station_id</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_station_name_count</th>\n",
       "      <td>end_station_name</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_station_id_count</th>\n",
       "      <td>end_station_id</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_lat_count</th>\n",
       "      <td>start_lat</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_lng_count</th>\n",
       "      <td>start_lng</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_lat_count</th>\n",
       "      <td>end_lat</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_lng_count</th>\n",
       "      <td>end_lng</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>member_casual_count</th>\n",
       "      <td>member_casual</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>started_at_count</th>\n",
       "      <td>started_at</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ended_at_count</th>\n",
       "      <td>ended_at</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Column  Missing Count Missing Percent\n",
       "_count                                                    0           0.00%\n",
       "ride_id_count                        ride_id              0           0.00%\n",
       "rideable_type_count            rideable_type              0           0.00%\n",
       "start_station_name_count  start_station_name              0           0.00%\n",
       "start_station_id_count      start_station_id              0           0.00%\n",
       "end_station_name_count      end_station_name              0           0.00%\n",
       "end_station_id_count          end_station_id              0           0.00%\n",
       "start_lat_count                    start_lat              0           0.00%\n",
       "start_lng_count                    start_lng              0           0.00%\n",
       "end_lat_count                        end_lat              0           0.00%\n",
       "end_lng_count                        end_lng              0           0.00%\n",
       "member_casual_count            member_casual              0           0.00%\n",
       "started_at_count                  started_at              0           0.00%\n",
       "ended_at_count                      ended_at              0           0.00%"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the function to calculate missing values on the DataFrame\n",
    "missing_values_cbs_c = calculate_missing_values(capitalbikeshare_clean)\n",
    "\n",
    "# Convert to Pandas DataFrame for better formatting\n",
    "missing_values_cbs_c_pandas = missing_values_cbs_c.toPandas()\n",
    "\n",
    "# Prepare the data for the desired output format\n",
    "missing_counts_cbs_c_final = pd.DataFrame({\n",
    "    'Column': [c.replace('_count', '') for c in missing_values_cbs_c_pandas.columns[:len(capitalbikeshare_clean.columns)]],\n",
    "    'Missing Count': missing_values_cbs_c_pandas.iloc[0, :len(capitalbikeshare_clean.columns)].astype(int),\n",
    "    'Missing Percent': missing_values_cbs_c_pandas.iloc[0, len(capitalbikeshare_clean.columns):].values\n",
    "})\n",
    "\n",
    "# Format the 'Missing Percent' column to show as a percentage with two decimal places\n",
    "missing_counts_cbs_c_final['Missing Percent'] = missing_counts_cbs_c_final['Missing Percent'].map(lambda x: '{:.2f}%'.format(x))\n",
    "\n",
    "missing_counts_cbs_c_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Both Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "# Convert the 'started_at' column to a date data type and store the result in a new column called 'start_date'\n",
    "capitalbikeshare_clean = capitalbikeshare_clean.withColumn(\n",
    "    \"start_date\", to_date(\"started_at\")\n",
    ")\n",
    "\n",
    "# Import the unix_timestamp function from the pyspark.sql.functions module\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "\n",
    "# Calculate the duration of each bike ride by finding the difference between the 'ended_at' and 'started_at' columns,\n",
    "# and store the result in a new column called 'duration'\n",
    "capitalbikeshare_clean = capitalbikeshare_clean.withColumn(\n",
    "    \"duration\", unix_timestamp(\"ended_at\") - unix_timestamp(\"started_at\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the 'start_date' column to the beginning of the 'capitalbikeshare_clean' DataFrame\n",
    "capitalbikeshare_clean = capitalbikeshare_clean.select('start_date', *capitalbikeshare_clean.drop('start_date').columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>77A0F1B26D1597B1</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>Rhode Island &amp; Connecticut Ave NW</td>\n",
       "      <td>31239.0</td>\n",
       "      <td>12th &amp; L St NW</td>\n",
       "      <td>31251.0</td>\n",
       "      <td>38.905994</td>\n",
       "      <td>-77.039803</td>\n",
       "      <td>38.903820</td>\n",
       "      <td>-77.028397</td>\n",
       "      <td>casual</td>\n",
       "      <td>2020-04-25 17:28:39</td>\n",
       "      <td>2020-04-25 17:35:04</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>1</td>\n",
       "      <td>8698F10128EA4F18</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>21st &amp; I St NW</td>\n",
       "      <td>31205.0</td>\n",
       "      <td>18th &amp; L St NW</td>\n",
       "      <td>31224.0</td>\n",
       "      <td>38.900711</td>\n",
       "      <td>-77.046448</td>\n",
       "      <td>38.903740</td>\n",
       "      <td>-77.042450</td>\n",
       "      <td>member</td>\n",
       "      <td>2020-04-06 07:54:59</td>\n",
       "      <td>2020-04-06 07:57:24</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>2</td>\n",
       "      <td>AA07819DC0F58872</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>Connecticut Ave &amp; Tilden St NW</td>\n",
       "      <td>31313.0</td>\n",
       "      <td>Connecticut Ave &amp; Tilden St NW</td>\n",
       "      <td>31313.0</td>\n",
       "      <td>38.941139</td>\n",
       "      <td>-77.061974</td>\n",
       "      <td>38.941139</td>\n",
       "      <td>-77.061974</td>\n",
       "      <td>casual</td>\n",
       "      <td>2020-04-22 17:06:18</td>\n",
       "      <td>2020-04-22 18:08:32</td>\n",
       "      <td>3734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>3</td>\n",
       "      <td>DA909BCA92EF85AB</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>7th &amp; E St SW</td>\n",
       "      <td>31294.0</td>\n",
       "      <td>7th &amp; E St SW</td>\n",
       "      <td>31294.0</td>\n",
       "      <td>38.883450</td>\n",
       "      <td>-77.021744</td>\n",
       "      <td>38.883450</td>\n",
       "      <td>-77.021744</td>\n",
       "      <td>casual</td>\n",
       "      <td>2020-04-16 15:22:40</td>\n",
       "      <td>2020-04-16 15:58:37</td>\n",
       "      <td>2157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>4</td>\n",
       "      <td>B36F1E14D8C6757E</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>Potomac &amp; Pennsylvania Ave SE</td>\n",
       "      <td>31606.0</td>\n",
       "      <td>8th &amp; Eye St SE / Barracks Row</td>\n",
       "      <td>31608.0</td>\n",
       "      <td>38.880299</td>\n",
       "      <td>-76.986198</td>\n",
       "      <td>38.879200</td>\n",
       "      <td>-76.995300</td>\n",
       "      <td>member</td>\n",
       "      <td>2020-04-10 13:19:41</td>\n",
       "      <td>2020-04-10 13:23:05</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date              ride_id rideable_type  \\\n",
       "0  2020-04-25  0  77A0F1B26D1597B1   docked_bike   \n",
       "1  2020-04-06  1  8698F10128EA4F18   docked_bike   \n",
       "2  2020-04-22  2  AA07819DC0F58872   docked_bike   \n",
       "3  2020-04-16  3  DA909BCA92EF85AB   docked_bike   \n",
       "4  2020-04-10  4  B36F1E14D8C6757E   docked_bike   \n",
       "\n",
       "                  start_station_name  start_station_id  \\\n",
       "0  Rhode Island & Connecticut Ave NW           31239.0   \n",
       "1                     21st & I St NW           31205.0   \n",
       "2     Connecticut Ave & Tilden St NW           31313.0   \n",
       "3                      7th & E St SW           31294.0   \n",
       "4      Potomac & Pennsylvania Ave SE           31606.0   \n",
       "\n",
       "                 end_station_name  end_station_id  start_lat  start_lng  \\\n",
       "0                  12th & L St NW         31251.0  38.905994 -77.039803   \n",
       "1                  18th & L St NW         31224.0  38.900711 -77.046448   \n",
       "2  Connecticut Ave & Tilden St NW         31313.0  38.941139 -77.061974   \n",
       "3                   7th & E St SW         31294.0  38.883450 -77.021744   \n",
       "4  8th & Eye St SE / Barracks Row         31608.0  38.880299 -76.986198   \n",
       "\n",
       "     end_lat    end_lng member_casual          started_at            ended_at  \\\n",
       "0  38.903820 -77.028397        casual 2020-04-25 17:28:39 2020-04-25 17:35:04   \n",
       "1  38.903740 -77.042450        member 2020-04-06 07:54:59 2020-04-06 07:57:24   \n",
       "2  38.941139 -77.061974        casual 2020-04-22 17:06:18 2020-04-22 18:08:32   \n",
       "3  38.883450 -77.021744        casual 2020-04-16 15:22:40 2020-04-16 15:58:37   \n",
       "4  38.879200 -76.995300        member 2020-04-10 13:19:41 2020-04-10 13:23:05   \n",
       "\n",
       "   duration  \n",
       "0       385  \n",
       "1       145  \n",
       "2      3734  \n",
       "3      2157  \n",
       "4       204  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitalbikeshare_clean.cache()\n",
    "capitalbikeshare_clean.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>tempmax</th>\n",
       "      <th>tempmin</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslikemax</th>\n",
       "      <th>feelslikemin</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precip</th>\n",
       "      <th>...</th>\n",
       "      <th>sealevelpressure</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>solarradiation</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>moonphase</th>\n",
       "      <th>sunlight_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>25.9</td>\n",
       "      <td>31.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>26.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>70.6</td>\n",
       "      <td>3.133</td>\n",
       "      <td>...</td>\n",
       "      <td>1011.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>71.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-07-01 05:46:51</td>\n",
       "      <td>2020-07-01 20:37:16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>14.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>33.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>33.7</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>36.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>73.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-07-02 05:47:21</td>\n",
       "      <td>2020-07-02 20:37:08</td>\n",
       "      <td>0.41</td>\n",
       "      <td>14.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>35.5</td>\n",
       "      <td>24.1</td>\n",
       "      <td>30.3</td>\n",
       "      <td>37.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1011.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-07-03 05:47:52</td>\n",
       "      <td>2020-07-03 20:36:58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>14.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>33.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>29.2</td>\n",
       "      <td>35.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>30.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>58.3</td>\n",
       "      <td>0.537</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.7</td>\n",
       "      <td>40.9</td>\n",
       "      <td>15.7</td>\n",
       "      <td>73.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-07-04 05:48:24</td>\n",
       "      <td>2020-07-04 20:36:45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>14.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>33.6</td>\n",
       "      <td>24.2</td>\n",
       "      <td>28.4</td>\n",
       "      <td>38.7</td>\n",
       "      <td>24.2</td>\n",
       "      <td>30.7</td>\n",
       "      <td>22.4</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1014.8</td>\n",
       "      <td>44.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>69.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-07-05 05:48:58</td>\n",
       "      <td>2020-07-05 20:36:31</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime  tempmax  tempmin  temp  feelslikemax  feelslikemin  feelslike  \\\n",
       "0 2020-07-01     30.0     22.6  25.9          31.6          22.6       26.5   \n",
       "1 2020-07-02     33.3     22.0  27.8          33.7          22.0       28.1   \n",
       "2 2020-07-03     35.5     24.1  30.3          37.0          24.1       31.0   \n",
       "3 2020-07-04     33.6     25.3  29.2          35.6          25.3       30.7   \n",
       "4 2020-07-05     33.6     24.2  28.4          38.7          24.2       30.7   \n",
       "\n",
       "    dew  humidity  precip  ...  sealevelpressure  cloudcover  visibility  \\\n",
       "0  20.0      70.6   3.133  ...            1011.5        54.0        16.0   \n",
       "1  18.0      57.9   0.000  ...            1012.0        36.9        16.0   \n",
       "2  18.0      49.2   0.000  ...            1011.7        20.4        16.0   \n",
       "3  20.0      58.3   0.537  ...            1012.7        40.9        15.7   \n",
       "4  22.4      71.3   0.000  ...            1014.8        44.3        13.5   \n",
       "\n",
       "   solarradiation  solarenergy  uvindex             sunrise  \\\n",
       "0            71.3          6.0        4 2020-07-01 05:46:51   \n",
       "1            73.5          6.2        4 2020-07-02 05:47:21   \n",
       "2            84.0          7.1        6 2020-07-03 05:47:52   \n",
       "3            73.0          6.2        4 2020-07-04 05:48:24   \n",
       "4            69.9          6.1        4 2020-07-05 05:48:58   \n",
       "\n",
       "               sunset  moonphase  sunlight_hours  \n",
       "0 2020-07-01 20:37:16       0.37           14.84  \n",
       "1 2020-07-02 20:37:08       0.41           14.83  \n",
       "2 2020-07-03 20:36:58       0.45           14.82  \n",
       "3 2020-07-04 20:36:45       0.48           14.81  \n",
       "4 2020-07-05 20:36:31       0.50           14.79  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherdata_clean.cache()\n",
    "weatherdata_clean.limit(5).toPandas()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_date: date (nullable = true)\n",
      " |-- : integer (nullable = true)\n",
      " |-- ride_id: string (nullable = true)\n",
      " |-- rideable_type: string (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_id: float (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_id: float (nullable = true)\n",
      " |-- start_lat: float (nullable = true)\n",
      " |-- start_lng: float (nullable = true)\n",
      " |-- end_lat: float (nullable = true)\n",
      " |-- end_lng: float (nullable = true)\n",
      " |-- member_casual: string (nullable = true)\n",
      " |-- started_at: timestamp (nullable = true)\n",
      " |-- ended_at: timestamp (nullable = true)\n",
      " |-- duration: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- datetime: timestamp (nullable = true)\n",
      " |-- tempmax: double (nullable = true)\n",
      " |-- tempmin: double (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- feelslikemax: double (nullable = true)\n",
      " |-- feelslikemin: double (nullable = true)\n",
      " |-- feelslike: double (nullable = true)\n",
      " |-- dew: double (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- precip: double (nullable = true)\n",
      " |-- precipprob: integer (nullable = true)\n",
      " |-- precipcover: double (nullable = true)\n",
      " |-- snow: double (nullable = true)\n",
      " |-- snowdepth: double (nullable = true)\n",
      " |-- windspeed: double (nullable = true)\n",
      " |-- winddir: double (nullable = true)\n",
      " |-- sealevelpressure: double (nullable = true)\n",
      " |-- cloudcover: double (nullable = true)\n",
      " |-- visibility: double (nullable = true)\n",
      " |-- solarradiation: double (nullable = true)\n",
      " |-- solarenergy: double (nullable = true)\n",
      " |-- uvindex: integer (nullable = true)\n",
      " |-- sunrise: timestamp (nullable = true)\n",
      " |-- sunset: timestamp (nullable = true)\n",
      " |-- moonphase: double (nullable = true)\n",
      " |-- sunlight_hours: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capitalbikeshare_clean row count: 10214972\n",
      "weatherdata_clean row count: 2133\n"
     ]
    }
   ],
   "source": [
    "capitalbikeshare_clean.printSchema()\n",
    "weatherdata_clean.printSchema()\n",
    "# Print the final row count for each DataFrame\n",
    "print(f\"capitalbikeshare_clean row count: {capitalbikeshare_clean.count()}\")\n",
    "print(f\"weatherdata_clean row count: {weatherdata_clean.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Join the DataFrames on the 'start_date' and 'datetime' columns\n",
    "biketrips_weather_total = capitalbikeshare_clean.join(\n",
    "    weatherdata_clean,\n",
    "    capitalbikeshare_clean.start_date == weatherdata_clean.datetime,\n",
    "    'left'\n",
    ")\n",
    "\n",
    "# Drop the 'datetime' column, since it is redundant with 'start_date'\n",
    "biketrips_weather_total = biketrips_weather_total.drop('datetime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>...</th>\n",
       "      <th>sealevelpressure</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>solarradiation</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>moonphase</th>\n",
       "      <th>sunlight_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>77A0F1B26D1597B1</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>Rhode Island &amp; Connecticut Ave NW</td>\n",
       "      <td>31239.0</td>\n",
       "      <td>12th &amp; L St NW</td>\n",
       "      <td>31251.0</td>\n",
       "      <td>38.905994</td>\n",
       "      <td>-77.039803</td>\n",
       "      <td>...</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-25 06:17:09</td>\n",
       "      <td>2020-04-25 19:55:29</td>\n",
       "      <td>0.09</td>\n",
       "      <td>13.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>1</td>\n",
       "      <td>8698F10128EA4F18</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>21st &amp; I St NW</td>\n",
       "      <td>31205.0</td>\n",
       "      <td>18th &amp; L St NW</td>\n",
       "      <td>31224.0</td>\n",
       "      <td>38.900711</td>\n",
       "      <td>-77.046448</td>\n",
       "      <td>...</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>46.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>182.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-04-06 06:44:13</td>\n",
       "      <td>2020-04-06 19:37:08</td>\n",
       "      <td>0.45</td>\n",
       "      <td>12.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>2</td>\n",
       "      <td>AA07819DC0F58872</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>Connecticut Ave &amp; Tilden St NW</td>\n",
       "      <td>31313.0</td>\n",
       "      <td>Connecticut Ave &amp; Tilden St NW</td>\n",
       "      <td>31313.0</td>\n",
       "      <td>38.941139</td>\n",
       "      <td>-77.061974</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.2</td>\n",
       "      <td>23.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>174.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-04-22 06:21:06</td>\n",
       "      <td>2020-04-22 19:52:34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>3</td>\n",
       "      <td>DA909BCA92EF85AB</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>7th &amp; E St SW</td>\n",
       "      <td>31294.0</td>\n",
       "      <td>7th &amp; E St SW</td>\n",
       "      <td>31294.0</td>\n",
       "      <td>38.883450</td>\n",
       "      <td>-77.021744</td>\n",
       "      <td>...</td>\n",
       "      <td>1021.6</td>\n",
       "      <td>30.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>178.1</td>\n",
       "      <td>15.2</td>\n",
       "      <td>8</td>\n",
       "      <td>2020-04-16 06:29:26</td>\n",
       "      <td>2020-04-16 19:46:46</td>\n",
       "      <td>0.79</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>4</td>\n",
       "      <td>B36F1E14D8C6757E</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>Potomac &amp; Pennsylvania Ave SE</td>\n",
       "      <td>31606.0</td>\n",
       "      <td>8th &amp; Eye St SE / Barracks Row</td>\n",
       "      <td>31608.0</td>\n",
       "      <td>38.880299</td>\n",
       "      <td>-76.986198</td>\n",
       "      <td>...</td>\n",
       "      <td>1005.7</td>\n",
       "      <td>42.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>114.3</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-04-10 06:38:11</td>\n",
       "      <td>2020-04-10 19:40:59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>13.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date              ride_id rideable_type  \\\n",
       "0  2020-04-25  0  77A0F1B26D1597B1   docked_bike   \n",
       "1  2020-04-06  1  8698F10128EA4F18   docked_bike   \n",
       "2  2020-04-22  2  AA07819DC0F58872   docked_bike   \n",
       "3  2020-04-16  3  DA909BCA92EF85AB   docked_bike   \n",
       "4  2020-04-10  4  B36F1E14D8C6757E   docked_bike   \n",
       "\n",
       "                  start_station_name  start_station_id  \\\n",
       "0  Rhode Island & Connecticut Ave NW           31239.0   \n",
       "1                     21st & I St NW           31205.0   \n",
       "2     Connecticut Ave & Tilden St NW           31313.0   \n",
       "3                      7th & E St SW           31294.0   \n",
       "4      Potomac & Pennsylvania Ave SE           31606.0   \n",
       "\n",
       "                 end_station_name  end_station_id  start_lat  start_lng  ...  \\\n",
       "0                  12th & L St NW         31251.0  38.905994 -77.039803  ...   \n",
       "1                  18th & L St NW         31224.0  38.900711 -77.046448  ...   \n",
       "2  Connecticut Ave & Tilden St NW         31313.0  38.941139 -77.061974  ...   \n",
       "3                   7th & E St SW         31294.0  38.883450 -77.021744  ...   \n",
       "4  8th & Eye St SE / Barracks Row         31608.0  38.880299 -76.986198  ...   \n",
       "\n",
       "   sealevelpressure  cloudcover visibility solarradiation solarenergy  \\\n",
       "0            1016.0        78.2       15.2           90.0         7.9   \n",
       "1            1017.0        46.4       16.0          182.6        15.7   \n",
       "2            1015.2        23.5       16.0          174.2        15.0   \n",
       "3            1021.6        30.2       16.0          178.1        15.2   \n",
       "4            1005.7        42.4       16.0          114.3         9.9   \n",
       "\n",
       "   uvindex             sunrise              sunset  moonphase  sunlight_hours  \n",
       "0        4 2020-04-25 06:17:09 2020-04-25 19:55:29       0.09           13.64  \n",
       "1        9 2020-04-06 06:44:13 2020-04-06 19:37:08       0.45           12.88  \n",
       "2        9 2020-04-22 06:21:06 2020-04-22 19:52:34       0.00           13.52  \n",
       "3        8 2020-04-16 06:29:26 2020-04-16 19:46:46       0.79           13.29  \n",
       "4        6 2020-04-10 06:38:11 2020-04-10 19:40:59       0.59           13.05  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biketrips_weather_total.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, tempmax: double, tempmin: double, temp: double, feelslikemax: double, feelslikemin: double, feelslike: double, dew: double, humidity: double, precip: double, precipprob: int, precipcover: double, snow: double, snowdepth: double, windspeed: double, winddir: double, sealevelpressure: double, cloudcover: double, visibility: double, solarradiation: double, solarenergy: double, uvindex: int, sunrise: timestamp, sunset: timestamp, moonphase: double, sunlight_hours: double]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitalbikeshare_clean.unpersist()\n",
    "weatherdata_clean.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>...</th>\n",
       "      <th>sealevelpressure</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>solarradiation</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>moonphase</th>\n",
       "      <th>sunlight_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>77A0F1B26D1597B1</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>Rhode Island &amp; Connecticut Ave NW</td>\n",
       "      <td>31239.0</td>\n",
       "      <td>12th &amp; L St NW</td>\n",
       "      <td>31251.0</td>\n",
       "      <td>38.905994</td>\n",
       "      <td>-77.039803</td>\n",
       "      <td>...</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-25 06:17:09</td>\n",
       "      <td>2020-04-25 19:55:29</td>\n",
       "      <td>0.09</td>\n",
       "      <td>13.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>1</td>\n",
       "      <td>8698F10128EA4F18</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>21st &amp; I St NW</td>\n",
       "      <td>31205.0</td>\n",
       "      <td>18th &amp; L St NW</td>\n",
       "      <td>31224.0</td>\n",
       "      <td>38.900711</td>\n",
       "      <td>-77.046448</td>\n",
       "      <td>...</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>46.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>182.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-04-06 06:44:13</td>\n",
       "      <td>2020-04-06 19:37:08</td>\n",
       "      <td>0.45</td>\n",
       "      <td>12.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>2</td>\n",
       "      <td>AA07819DC0F58872</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>Connecticut Ave &amp; Tilden St NW</td>\n",
       "      <td>31313.0</td>\n",
       "      <td>Connecticut Ave &amp; Tilden St NW</td>\n",
       "      <td>31313.0</td>\n",
       "      <td>38.941139</td>\n",
       "      <td>-77.061974</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.2</td>\n",
       "      <td>23.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>174.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-04-22 06:21:06</td>\n",
       "      <td>2020-04-22 19:52:34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>3</td>\n",
       "      <td>DA909BCA92EF85AB</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>7th &amp; E St SW</td>\n",
       "      <td>31294.0</td>\n",
       "      <td>7th &amp; E St SW</td>\n",
       "      <td>31294.0</td>\n",
       "      <td>38.883450</td>\n",
       "      <td>-77.021744</td>\n",
       "      <td>...</td>\n",
       "      <td>1021.6</td>\n",
       "      <td>30.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>178.1</td>\n",
       "      <td>15.2</td>\n",
       "      <td>8</td>\n",
       "      <td>2020-04-16 06:29:26</td>\n",
       "      <td>2020-04-16 19:46:46</td>\n",
       "      <td>0.79</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>4</td>\n",
       "      <td>B36F1E14D8C6757E</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>Potomac &amp; Pennsylvania Ave SE</td>\n",
       "      <td>31606.0</td>\n",
       "      <td>8th &amp; Eye St SE / Barracks Row</td>\n",
       "      <td>31608.0</td>\n",
       "      <td>38.880299</td>\n",
       "      <td>-76.986198</td>\n",
       "      <td>...</td>\n",
       "      <td>1005.7</td>\n",
       "      <td>42.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>114.3</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-04-10 06:38:11</td>\n",
       "      <td>2020-04-10 19:40:59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>13.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date              ride_id rideable_type  \\\n",
       "0  2020-04-25  0  77A0F1B26D1597B1   docked_bike   \n",
       "1  2020-04-06  1  8698F10128EA4F18   docked_bike   \n",
       "2  2020-04-22  2  AA07819DC0F58872   docked_bike   \n",
       "3  2020-04-16  3  DA909BCA92EF85AB   docked_bike   \n",
       "4  2020-04-10  4  B36F1E14D8C6757E   docked_bike   \n",
       "\n",
       "                  start_station_name  start_station_id  \\\n",
       "0  Rhode Island & Connecticut Ave NW           31239.0   \n",
       "1                     21st & I St NW           31205.0   \n",
       "2     Connecticut Ave & Tilden St NW           31313.0   \n",
       "3                      7th & E St SW           31294.0   \n",
       "4      Potomac & Pennsylvania Ave SE           31606.0   \n",
       "\n",
       "                 end_station_name  end_station_id  start_lat  start_lng  ...  \\\n",
       "0                  12th & L St NW         31251.0  38.905994 -77.039803  ...   \n",
       "1                  18th & L St NW         31224.0  38.900711 -77.046448  ...   \n",
       "2  Connecticut Ave & Tilden St NW         31313.0  38.941139 -77.061974  ...   \n",
       "3                   7th & E St SW         31294.0  38.883450 -77.021744  ...   \n",
       "4  8th & Eye St SE / Barracks Row         31608.0  38.880299 -76.986198  ...   \n",
       "\n",
       "   sealevelpressure  cloudcover visibility solarradiation solarenergy  \\\n",
       "0            1016.0        78.2       15.2           90.0         7.9   \n",
       "1            1017.0        46.4       16.0          182.6        15.7   \n",
       "2            1015.2        23.5       16.0          174.2        15.0   \n",
       "3            1021.6        30.2       16.0          178.1        15.2   \n",
       "4            1005.7        42.4       16.0          114.3         9.9   \n",
       "\n",
       "   uvindex             sunrise              sunset  moonphase  sunlight_hours  \n",
       "0        4 2020-04-25 06:17:09 2020-04-25 19:55:29       0.09           13.64  \n",
       "1        9 2020-04-06 06:44:13 2020-04-06 19:37:08       0.45           12.88  \n",
       "2        9 2020-04-22 06:21:06 2020-04-22 19:52:34       0.00           13.52  \n",
       "3        8 2020-04-16 06:29:26 2020-04-16 19:46:46       0.79           13.29  \n",
       "4        6 2020-04-10 06:38:11 2020-04-10 19:40:59       0.59           13.05  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cache the joined DataFrame for faster access\n",
    "biketrips_weather_total.cache()\n",
    "\n",
    "# Display the first few rows of the joined DataFrame\n",
    "biketrips_weather_total.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/10 00:33:35 ERROR Executor: Exception in task 4.0 in stage 118.0 (TID 560)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.sql.catalyst.util.Iso8601TimestampFormatter$$Lambda$3766/0x000000010166a840.get$Lambda(Unknown Source)\n",
      "\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeStatic(DirectMethodHandle$Holder)\n",
      "\tat java.base/java.lang.invoke.Invokers$Holder.linkToTargetMethod(Invokers$Holder)\n",
      "\tat org.apache.spark.sql.catalyst.util.Iso8601TimestampFormatter.parse(TimestampFormatter.scala:117)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:87)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:79)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.storage.memory.PartiallyUnrolledIterator.next(MemoryStore.scala:783)\n",
      "\tat org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)\n",
      "\tat org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:177)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3(BlockManager.scala:1500)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3$adapted(BlockManager.scala:1498)\n",
      "\tat org.apache.spark.storage.BlockManager$$Lambda$3521/0x00000001015b1840.apply(Unknown Source)\n",
      "\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:70)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1498)\n",
      "\tat org.apache.spark.storage.BlockManager$$Lambda$2054/0x0000000101081840.apply(Unknown Source)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1418)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1482)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1305)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "23/11/10 00:33:35 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 4.0 in stage 118.0 (TID 560),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.sql.catalyst.util.Iso8601TimestampFormatter$$Lambda$3766/0x000000010166a840.get$Lambda(Unknown Source)\n",
      "\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeStatic(DirectMethodHandle$Holder)\n",
      "\tat java.base/java.lang.invoke.Invokers$Holder.linkToTargetMethod(Invokers$Holder)\n",
      "\tat org.apache.spark.sql.catalyst.util.Iso8601TimestampFormatter.parse(TimestampFormatter.scala:117)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:87)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:79)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.storage.memory.PartiallyUnrolledIterator.next(MemoryStore.scala:783)\n",
      "\tat org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)\n",
      "\tat org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:177)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3(BlockManager.scala:1500)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3$adapted(BlockManager.scala:1498)\n",
      "\tat org.apache.spark.storage.BlockManager$$Lambda$3521/0x00000001015b1840.apply(Unknown Source)\n",
      "\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:70)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1498)\n",
      "\tat org.apache.spark.storage.BlockManager$$Lambda$2054/0x0000000101081840.apply(Unknown Source)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1418)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1482)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1305)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "23/11/10 00:33:35 ERROR TaskSetManager: Task 4 in stage 118.0 failed 1 times; aborting job\n",
      "23/11/10 00:33:36 ERROR TaskSchedulerImpl: Exception in statusUpdate1 + 1) / 17]\n",
      "java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$Lambda$4025/0x000000010116dc40@79d4cd92 rejected from java.util.concurrent.ThreadPoolExecutor@e367099[Terminated, pool size = 2, active threads = 0, queued tasks = 0, completed tasks = 564]\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)\n",
      "\tat org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:137)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:817)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:791)\n",
      "\tat org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:71)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1891.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 118.0 failed 1 times, most recent failure: Lost task 4.0 in stage 118.0 (TID 560) (10.0.2.15 executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.sql.catalyst.util.Iso8601TimestampFormatter$$Lambda$3766/0x000000010166a840.get$Lambda(Unknown Source)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeStatic(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.Invokers$Holder.linkToTargetMethod(Invokers$Holder)\n\tat org.apache.spark.sql.catalyst.util.Iso8601TimestampFormatter.parse(TimestampFormatter.scala:117)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:87)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:79)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.storage.memory.PartiallyUnrolledIterator.next(MemoryStore.scala:783)\n\tat org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)\n\tat org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:177)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3(BlockManager.scala:1500)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3$adapted(BlockManager.scala:1498)\n\tat org.apache.spark.storage.BlockManager$$Lambda$3521/0x00000001015b1840.apply(Unknown Source)\n\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:70)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1498)\n\tat org.apache.spark.storage.BlockManager$$Lambda$2054/0x0000000101081840.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1418)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1482)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1305)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.sql.catalyst.util.Iso8601TimestampFormatter$$Lambda$3766/0x000000010166a840.get$Lambda(Unknown Source)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeStatic(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.Invokers$Holder.linkToTargetMethod(Invokers$Holder)\n\tat org.apache.spark.sql.catalyst.util.Iso8601TimestampFormatter.parse(TimestampFormatter.scala:117)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:87)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:79)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.storage.memory.PartiallyUnrolledIterator.next(MemoryStore.scala:783)\n\tat org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)\n\tat org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:177)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3(BlockManager.scala:1500)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3$adapted(BlockManager.scala:1498)\n\tat org.apache.spark.storage.BlockManager$$Lambda$3521/0x00000001015b1840.apply(Unknown Source)\n\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:70)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1498)\n\tat org.apache.spark.storage.BlockManager$$Lambda$2054/0x0000000101081840.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1418)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1482)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1305)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mj:\\IE\\SECOND TERM\\MODERN DATA II\\Spark Notebooks\\Preprocesssing_MDA2_GA_v3.ipynb Cell 70\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/j%3A/IE/SECOND%20TERM/MODERN%20DATA%20II/Spark%20Notebooks/Preprocesssing_MDA2_GA_v3.ipynb#Y124sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m missing_values \u001b[39m=\u001b[39m biketrips_weather_total\u001b[39m.\u001b[39mselect([\u001b[39msum\u001b[39m(col(c)\u001b[39m.\u001b[39misNull()\u001b[39m.\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39mint\u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39malias(c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m biketrips_weather_total\u001b[39m.\u001b[39mcolumns])\n\u001b[1;32m      <a href='vscode-notebook-cell:/j%3A/IE/SECOND%20TERM/MODERN%20DATA%20II/Spark%20Notebooks/Preprocesssing_MDA2_GA_v3.ipynb#Y124sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Display the results\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/j%3A/IE/SECOND%20TERM/MODERN%20DATA%20II/Spark%20Notebooks/Preprocesssing_MDA2_GA_v3.ipynb#Y124sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m missing_values\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[0;32m/opt/spark3/python/pyspark/sql/dataframe.py:494\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mParameter \u001b[39m\u001b[39m'\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a bool\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    493\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(truncate, \u001b[39mbool\u001b[39m) \u001b[39mand\u001b[39;00m truncate:\n\u001b[0;32m--> 494\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mshowString(n, \u001b[39m20\u001b[39;49m, vertical))\n\u001b[1;32m    495\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/spark3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/spark3/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    112\u001b[0m     \u001b[39mexcept\u001b[39;00m py4j\u001b[39m.\u001b[39mprotocol\u001b[39m.\u001b[39mPy4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/spark3/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1891.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 118.0 failed 1 times, most recent failure: Lost task 4.0 in stage 118.0 (TID 560) (10.0.2.15 executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.sql.catalyst.util.Iso8601TimestampFormatter$$Lambda$3766/0x000000010166a840.get$Lambda(Unknown Source)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeStatic(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.Invokers$Holder.linkToTargetMethod(Invokers$Holder)\n\tat org.apache.spark.sql.catalyst.util.Iso8601TimestampFormatter.parse(TimestampFormatter.scala:117)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:87)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:79)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.storage.memory.PartiallyUnrolledIterator.next(MemoryStore.scala:783)\n\tat org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)\n\tat org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:177)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3(BlockManager.scala:1500)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3$adapted(BlockManager.scala:1498)\n\tat org.apache.spark.storage.BlockManager$$Lambda$3521/0x00000001015b1840.apply(Unknown Source)\n\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:70)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1498)\n\tat org.apache.spark.storage.BlockManager$$Lambda$2054/0x0000000101081840.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1418)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1482)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1305)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.sql.catalyst.util.Iso8601TimestampFormatter$$Lambda$3766/0x000000010166a840.get$Lambda(Unknown Source)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeStatic(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.Invokers$Holder.linkToTargetMethod(Invokers$Holder)\n\tat org.apache.spark.sql.catalyst.util.Iso8601TimestampFormatter.parse(TimestampFormatter.scala:117)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:87)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:79)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.storage.memory.PartiallyUnrolledIterator.next(MemoryStore.scala:783)\n\tat org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)\n\tat org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:177)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3(BlockManager.scala:1500)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3$adapted(BlockManager.scala:1498)\n\tat org.apache.spark.storage.BlockManager$$Lambda$3521/0x00000001015b1840.apply(Unknown Source)\n\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:70)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1498)\n\tat org.apache.spark.storage.BlockManager$$Lambda$2054/0x0000000101081840.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1418)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1482)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1305)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# Count the number of missing values in each column of the joined DataFrame\n",
    "missing_values = biketrips_weather_total.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in biketrips_weather_total.columns])\n",
    "\n",
    "# Display the results\n",
    "missing_values.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write the DataFrame back to HDFS in a processed format, like Parquet\n",
    "biketrips_weather_total.write.parquet(\"hdfs://localhost:9000/datalake/std/bikes_sharing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1fcec",
   "metadata": {},
   "source": [
    "## End Spark Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb3b687",
   "metadata": {},
   "source": [
    "### Unpersist to free up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "782e8d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[start_date: date, : int, ride_id: string, rideable_type: string, start_station_name: string, start_station_id: float, end_station_name: string, end_station_id: float, start_lat: float, start_lng: float, end_lat: float, end_lng: float, member_casual: string, started_at: timestamp, ended_at: timestamp, duration: bigint, tempmax: double, tempmin: double, temp: double, feelslikemax: double, feelslikemin: double, feelslike: double, dew: double, humidity: double, precip: double, precipprob: int, precipcover: double, snow: double, snowdepth: double, windspeed: double, winddir: double, sealevelpressure: double, cloudcover: double, visibility: double, solarradiation: double, solarenergy: double, uvindex: int, sunrise: timestamp, sunset: timestamp, moonphase: double, sunlight_hours: double]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biketrips_weather_total.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d971b",
   "metadata": {},
   "source": [
    "### Tear Down\n",
    "\n",
    "Once we complete the the lab we can stop all the services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a672d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f04d588b",
   "metadata": {},
   "source": [
    "### Stop Hadoop\n",
    "\n",
    "Stops Hadoop\n",
    "Open a terminal and execute\n",
    "```sh\n",
    "hadoop-stop.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f21078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
